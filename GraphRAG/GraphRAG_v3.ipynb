{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation with LlamaIndex - V2\n",
    "\n",
    "[GraphRAG (Graphs + Retrieval Augmented Generation)](https://www.microsoft.com/en-us/research/project/graphrag/) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
    "\n",
    "This notebook provides guidance on constructing the GraphRAG pipeline using the LlamaIndex PropertyGraph abstractions using Neo4J.\n",
    "\n",
    "This notebook updates the GraphRAG pipeline to v2. If you haven’t checked v1 yet, you can find it [here](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb). Following are the updates to the existing implementation:\n",
    "\n",
    "1. Integrate with Neo4J Graph database.\n",
    "2. Embedding based retrieval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "`graspologic` is used to use hierarchical_leiden for building communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-graph-stores-neo4j graspologic numpy==1.26.4 scipy==1.12.0 future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will use a sample news article dataset retrieved from Diffbot, which Tomaz has conveniently made available on GitHub for easy access.\n",
    "\n",
    "The dataset contains 2,500 samples; for ease of experimentation, we will use 50 of these samples, which include the `title` and `text` of news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSMC and MediaTek Deepen Alliance with 3nm Pro...</td>\n",
       "      <td>Foundry giant TSMC continues to be the manufac...</td>\n",
       "      <td>semiconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MediaTek Taps TSMC's 3nm Process for New Dimen...</td>\n",
       "      <td>Global mobile chipset design leader MediaTek i...</td>\n",
       "      <td>semiconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UMC's Specialty Process Expansion Poised to Su...</td>\n",
       "      <td>Foundry major United Microelectronics Corporat...</td>\n",
       "      <td>semiconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIS Capacity Expansion for Specialty DDIs to B...</td>\n",
       "      <td>Vanguard International Semiconductor's (VIS) p...</td>\n",
       "      <td>semiconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PSMC's Mature Process Capabilities Crucial for...</td>\n",
       "      <td>Powerchip Semiconductor Manufacturing Corp (PS...</td>\n",
       "      <td>semiconductor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  TSMC and MediaTek Deepen Alliance with 3nm Pro...   \n",
       "1  MediaTek Taps TSMC's 3nm Process for New Dimen...   \n",
       "2  UMC's Specialty Process Expansion Poised to Su...   \n",
       "3  VIS Capacity Expansion for Specialty DDIs to B...   \n",
       "4  PSMC's Mature Process Capabilities Crucial for...   \n",
       "\n",
       "                                                text       industry  \n",
       "0  Foundry giant TSMC continues to be the manufac...  semiconductor  \n",
       "1  Global mobile chipset design leader MediaTek i...  semiconductor  \n",
       "2  Foundry major United Microelectronics Corporat...  semiconductor  \n",
       "3  Vanguard International Semiconductor's (VIS) p...  semiconductor  \n",
       "4  Powerchip Semiconductor Manufacturing Corp (PS...  semiconductor  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document\n",
    "\n",
    "news = pd.read_csv(\n",
    "    \"data.csv\",\n",
    "    dtype={\"industry\": str}\n",
    ")[:50]\n",
    "\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     32 non-null     object\n",
      " 1   text      32 non-null     object\n",
      " 2   industry  32 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 900.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare documents as required by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        text=f\"{row['title']}: {row['text']}\",\n",
    "        metadata={\"industry\": row[\"industry\"]} # 將行業資訊放入 metadata\n",
    "    )\n",
    "    for i, row in news.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API Key and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 從 .env 檔案載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGExtractor\n",
    "\n",
    "The GraphRAGExtractor class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
    "\n",
    "This functionality is similar to that of the `SimpleLLMPathExtractor`, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing [extractors](https://docs.llamaindex.ai/en/latest/examples/property_graph/Dynamic_KG_Extraction/?h=comparing).\n",
    "\n",
    "Here's a breakdown of its functionality:\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. `llm:` The language model used for extraction.\n",
    "2. `extract_prompt:` A prompt template used to guide the LLM in extracting information.\n",
    "3. `parse_fn:` A function to parse the LLM's output into structured data.\n",
    "4. `max_paths_per_chunk:` Limits the number of triples extracted per text chunk.\n",
    "5. `num_workers:` For parallel processing of multiple text nodes.\n",
    "\n",
    "\n",
    "**Main Methods:**\n",
    "\n",
    "1. `__call__:` The entry point for processing a list of text nodes.\n",
    "2. `acall:` An asynchronous version of __call__ for improved performance.\n",
    "3. `_aextract:` The core method that processes each individual node.\n",
    "\n",
    "\n",
    "**Extraction Process:**\n",
    "\n",
    "For each input node (chunk of text):\n",
    "1. It sends the text to the LLM along with the extraction prompt.\n",
    "2. The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
    "3. Entities are converted into EntityNode objects. Entity description is stored in metadata\n",
    "4. Relationships are converted into Relation objects. Relationship description is stored in metadata.\n",
    "5. These are added to the node's metadata under KG_NODES_KEY and KG_RELATIONS_KEY.\n",
    "\n",
    "**NOTE:** In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            entity_metadata[\"entity_description\"] = description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGStore\n",
    "\n",
    "The `GraphRAGStore` class is an extension of the `Neo4jPropertyGraphStore`class, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
    "\n",
    "\n",
    "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`build_communities():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph.\n",
    "\n",
    "2. Applies the hierarchical Leiden algorithm for community detection.\n",
    "\n",
    "3. Collects detailed information about each community.\n",
    "\n",
    "4. Generates summaries for each community.\n",
    "\n",
    "`generate_community_summary(text):`\n",
    "\n",
    "1. Uses LLM to generate a summary of the relationships in a community.\n",
    "2. The summary includes entity names and a synthesis of relationship descriptions.\n",
    "\n",
    "`_create_nx_graph():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph for community detection.\n",
    "\n",
    "`_collect_community_info(nx_graph, clusters):`\n",
    "\n",
    "1. Collects detailed information about each node based on its community.\n",
    "2. Creates a string representation of each relationship within a community.\n",
    "\n",
    "`_summarize_communities(community_info):`\n",
    "\n",
    "1. Generates and stores summaries for each community using LLM.\n",
    "\n",
    "`get_community_summaries():`\n",
    "\n",
    "1. Returns the community summaries by building them if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZieWeiXie\\anaconda3\\envs\\GraphRAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from collections import defaultdict\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "\n",
    "class GraphRAGStore(Neo4jPropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    entity_info = None\n",
    "    max_cluster_size = 24\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are an expert industry analyst. Your task is to create a structured and insightful analysis report \"\n",
    "                    \"for an industry community based on a list of relationships from a knowledge graph.\\n\\n\"\n",
    "                    \"**Goal:** Generate a comprehensive summary in Markdown format that analyzes the provided relationships \"\n",
    "                    \"within the given industry community.\\n\\n\"\n",
    "                    \"**Input Data:** You will receive a list of raw relationship strings. Each string follows the format: \"\n",
    "                    \"\\\"entity1 -> entity2 -> relation -> relationship_description\\\".\\n\\n\"\n",
    "                    \"**Output Format (Strictly follow this Markdown structure):**\\n\\n\"\n",
    "                    \"# [Industry Name] Industry Community Analysis\\n\\n\"\n",
    "                    \"## 1. Overview\\n\"\n",
    "                    \"(Provide a brief, 2-3 sentence introduction to this industry based on the entities and their interactions. \"\n",
    "                    \"Describe its main characteristics.)\\n\\n\"\n",
    "                    \"## 2. Key Players\\n\"\n",
    "                    \"(Based on the frequency of their appearance and centrality in the relationships, identify 3-5 of the most \"\n",
    "                    \"important companies in this community. List them as bullet points.)\\n\\n\"\n",
    "                    \"## 3. Relationship Analysis\\n\"\n",
    "                    \"(Categorize the provided relationships into the following sub-sections. Use the 'relation' and \"\n",
    "                    \"'relationship_description' to determine the category. If a category has no relevant relationships, \"\n",
    "                    \"OMIT the entire sub-section from the output.)\\n\\n\"\n",
    "                    \"### Competitive Landscape\\n\"\n",
    "                    \"(Summarize the direct competition between companies. Example: 'Company A is in fierce competition with Company B...')\\n\\n\"\n",
    "                    \"### Supply Chain & Partnerships\\n\"\n",
    "                    \"(Describe the supplier-client relationships, strategic partnerships, and collaborations. Example: 'Company C is \"\n",
    "                    \"a key supplier to Company D, providing essential components...')\\n\\n\"\n",
    "                    \"## 4. Key Insights\\n\"\n",
    "                    \"(Based on your analysis, provide a concluding paragraph summarizing the overall dynamics of this industry community. \"\n",
    "                    \"What are the key trends, dependencies, or notable characteristics?)\\n\\n\"\n",
    "                    \"---\\n\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = OpenAI().chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    # 在 GraphRAGStore class 中\n",
    "    def build_communities(self):\n",
    "        \"\"\"\n",
    "        Builds communities based on the 'industry' property of Company nodes,\n",
    "        instead of using a structural algorithm like Leiden.\n",
    "        \"\"\"\n",
    "        print(\"Building communities based on 'industry' attribute...\")\n",
    "        \n",
    "        # 步驟 a: 查詢所有公司及其行業屬性\n",
    "        # 假設您的公司節點標籤是 'Company'，行業屬性是 'industry'\n",
    "        # 請根據您的實際圖譜綱要調整\n",
    "        query = \"\"\"\n",
    "        MATCH (c:Company)\n",
    "        WHERE c.industry IS NOT NULL\n",
    "        RETURN c.name AS entity, c.industry AS community\n",
    "        \"\"\"\n",
    "        with self._driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            records = list(result)\n",
    "\n",
    "        # 步驟 b: 按行業對公司進行分組\n",
    "        communities_by_industry = defaultdict(list)\n",
    "        for record in records:\n",
    "            communities_by_industry[record[\"community\"]].append(record[\"entity\"])\n",
    "\n",
    "        # 步驟 c: 將分組結果轉換為所需的格式\n",
    "        entity_info = defaultdict(list)\n",
    "        community_info = defaultdict(list)\n",
    "        \n",
    "        nx_graph = self._create_nx_graph() # 我們仍然需要它來獲取關係細節\n",
    "\n",
    "        for industry, entities in communities_by_industry.items():\n",
    "            community_id = industry  # 直接使用行業名稱作為社群ID\n",
    "            \n",
    "            for entity in entities:\n",
    "                entity_info[entity].append(community_id)\n",
    "                \n",
    "                # 獲取這個社群內部的所有關係細節\n",
    "                for neighbor in nx_graph.neighbors(entity):\n",
    "                    # 確保鄰居也在同一個行業社群中\n",
    "                    if neighbor in entities:\n",
    "                        edge_data = nx_graph.get_edge_data(entity, neighbor)\n",
    "                        if edge_data:\n",
    "                            detail = f\"{entity} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                            community_info[community_id].append(detail)\n",
    "        \n",
    "        self.entity_info = dict(entity_info)\n",
    "        \n",
    "        # 步驟 d: 為每個行業社群生成摘要\n",
    "        self._summarize_communities(dict(community_info))\n",
    "\n",
    "        print(f\"Successfully built {len(community_info)} communities based on industry.\")\n",
    "        \n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            nx_graph.add_node(entity1.name)\n",
    "            nx_graph.add_node(entity2.name)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"\n",
    "        Collect information for each node based on their community,\n",
    "        allowing entities to belong to multiple clusters.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity_info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGQueryEngine\n",
    "\n",
    "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
    "\n",
    "**Main Components:**\n",
    "\n",
    "`graph_store:` An instance of GraphRAGStore, which contains the community summaries.\n",
    "`llm:` A Language Model (LLM) used for generating and aggregating answers.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`custom_query(query_str: str)`\n",
    "\n",
    "1. This is the main entry point for processing a query. It retrieves community summaries, generates answers from each summary, and then aggregates these answers into a final response.\n",
    "\n",
    "`generate_answer_from_summary(community_summary, query):`\n",
    "\n",
    "1. Generates an answer for the query based on a single community summary.\n",
    "Uses the LLM to interpret the community summary in the context of the query.\n",
    "\n",
    "`aggregate_answers(community_answers):`\n",
    "\n",
    "1. Combines individual answers from different communities into a coherent final response.\n",
    "2. Uses the LLM to synthesize multiple perspectives into a single, concise answer.\n",
    "\n",
    "\n",
    "**Query Processing Flow:**\n",
    "\n",
    "1. Retrieve community summaries from the graph store.\n",
    "2. For each community summary, generate a specific answer to the query.\n",
    "3. Aggregate all community-specific answers into a final, coherent response.\n",
    "\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```\n",
    "query_engine = GraphRAGQueryEngine(graph_store=graph_store, llm=llm)\n",
    "\n",
    "response = query_engine.query(\"query\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM\n",
    "    similarity_top_k: int = 20\n",
    "    def _get_related_entities_from_graph(self, query_str: str, depth: int = 1) -> list[str]:\n",
    "        \"\"\"\n",
    "        Identifies anchor entities from the query and expands them by fetching their\n",
    "        direct neighbors from the graph.\n",
    "        \"\"\"\n",
    "        # 步驟 1: 從問題中識別出「錨點實體」 (沿用舊邏輯)\n",
    "        anchor_entities = self._get_entities_from_query(query_str)\n",
    "        \n",
    "        if not anchor_entities:\n",
    "            print(\"No anchor entities found in query.\")\n",
    "            return []\n",
    "\n",
    "        print(f\"Found anchor entities: {anchor_entities}\")\n",
    "\n",
    "        # 使用 set 來存放所有相關實體，自動處理重複\n",
    "        all_related_entities = set(anchor_entities)\n",
    "\n",
    "        # 步驟 2: 對於每個錨點實體，去圖譜中查詢其鄰居\n",
    "        # 注意：這裡的 self.graph_store 需要有執行 cypher 的能力，或者直接使用 neo4j driver\n",
    "        with self.graph_store._driver.session() as session:\n",
    "            for entity_name in anchor_entities:\n",
    "                # Cypher 查詢：找到指定節點的所有一度鄰居\n",
    "                cypher_query = f\"\"\"\n",
    "                MATCH (start_node {{name: $entity_name}})-[r]-(neighbor)\n",
    "                RETURN neighbor.name AS neighbor_name\n",
    "                \"\"\"\n",
    "                result = session.run(cypher_query, entity_name=entity_name)\n",
    "                \n",
    "                neighbors = [record[\"neighbor_name\"] for record in result]\n",
    "                all_related_entities.update(neighbors)\n",
    "\n",
    "        final_entity_list = list(all_related_entities)\n",
    "        print(f\"Expanded to related entities: {final_entity_list}\")\n",
    "        \n",
    "        return final_entity_list\n",
    "\n",
    "    def _get_entities_from_query(self, query_str: str) -> List[str]:\n",
    "        \"\"\"A simple method to extract known entities directly from the query string.\"\"\"\n",
    "        \n",
    "        # 獲取知識圖譜中所有已知實體的名稱\n",
    "        known_entities = self.graph_store.entity_info.keys()\n",
    "        \n",
    "        found_entities = []\n",
    "        # 遍歷所有已知實體，檢查它們是否出現在查詢問題中\n",
    "        for entity in known_entities:\n",
    "            # 使用正則表達式進行全詞匹配，避免 \"ASUS\" 匹配到 \"ASU\" 等情況\n",
    "            # re.IGNORECASE 讓匹配不分大小寫\n",
    "            if re.search(r'\\b' + re.escape(entity) + r'\\b', query_str, re.IGNORECASE):\n",
    "                found_entities.append(entity)\n",
    "        \n",
    "        print(f\"Found entities in query: {found_entities}\") # 添加日誌便於除錯\n",
    "        return found_entities\n",
    "    \n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "\n",
    "        entities = self._get_related_entities_from_graph(query_str)\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            self.graph_store.entity_info, entities\n",
    "        )\n",
    "        \n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for id, community_summary in community_summaries.items()\n",
    "            if id in community_ids\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def get_entities(self, query_str, similarity_top_k):\n",
    "        nodes_retrieved = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        enitites = set()\n",
    "        pattern = (\n",
    "            r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    "        )\n",
    "\n",
    "        for node in nodes_retrieved:\n",
    "            matches = re.findall(\n",
    "                pattern, node.text, re.MULTILINE | re.IGNORECASE\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                enitites.add(subject)\n",
    "                enitites.add(obj)\n",
    "\n",
    "        return list(enitites)\n",
    "\n",
    "    def retrieve_entity_communities(self, entity_info, entities):\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "        entity_info (dict): Dictionary mapping entities to their cluster IDs (list).\n",
    "        entities (list): List of entity names to retrieve information for.\n",
    "\n",
    "        Returns:\n",
    "        List of community or cluster IDs to which an entity belongs.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build End to End GraphRAG Pipeline\n",
    "\n",
    "Now that we have defined all the necessary components, let’s construct the GraphRAG pipeline:\n",
    "\n",
    "1. Create nodes/chunks from the text.\n",
    "2. Build a PropertyGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`.\n",
    "3. Construct communities and generate a summary for each community using the graph built above.\n",
    "4. Create a `GraphRAGQueryEngine` and begin querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes/ chunks from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ProperGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all companies and the relationships among them. The goal is to create a knowledge graph of corporate interactions.\n",
    "\n",
    "Given the text, extract up to {max_knowledge_triplets} company-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "\n",
    "Identify all Company Entities. For each identified company, extract the following information:\n",
    "\n",
    "entity_name: The official or most common name of the company. Crucially, you MUST normalize variations into a single, consistent name (e.g., if you see \"Tsmc\" or \"tsmc\", you must output \"TSMC\"; for \"Global Devices Corp.\", always use this full name, not \"Global Devices\").\n",
    "entity_type: Always use \"Company\".\n",
    "entity_description: A comprehensive description of the company's business, industry, and key activities mentioned in the text.\n",
    "Identify Inter-Company Relationships. From the companies identified in step 1, identify all pairs of (source_entity, target_entity) that have a clear and direct relationship described in the text.\n",
    "For each pair of related companies, extract the following information:\n",
    "\n",
    "source_entity: Name of the source company, as identified in step 1.\n",
    "target_entity: Name of the target company, as identified in step 1.\n",
    "relation: A standardized relationship type that best describes the connection. Use one of the following predefined types: COMPETES_WITH, IS_PARTNER_OF, IS_SUPPLIER_TO, IS_CUSTOMER_OF, INVESTED_IN, ACQUIRED, IS_PARENT_COMPANY_OF, OTHER.\n",
    "relationship_description: A concise explanation, citing evidence from the text, as to why you think the two companies are related.\n",
    "Output Formatting:\n",
    "\n",
    "Return the result in a valid JSON format with two keys: entities (a list of company objects) and relationships (a list of relationship objects).\n",
    "Exclude any text or explanations outside the main JSON structure.\n",
    "If no companies or relationships are identified, return empty lists: { \"entities\": [], \"relationships\": [] }.\n",
    "-An Output Example-\n",
    "{\n",
    "    \"entities\": [\n",
    "        {\n",
    "            \"entity_name\": \"QuantumChip Inc.\",\n",
    "            \"entity_type\": \"Company\",\n",
    "            \"entity_description\": \"QuantumChip Inc. is a leading designer of AI accelerators, securing a supply agreement for next-generation smartphones.\"\n",
    "        },\n",
    "        {\n",
    "            \"entity_name\": \"Global Devices Corp.\",\n",
    "            \"entity_type\": \"Company\",\n",
    "            \"entity_description\": \"Global Devices Corp. is a major smartphone manufacturer that will use QuantumChip's accelerators in its next-generation flagship phone.\"\n",
    "        },\n",
    "        {\n",
    "            \"entity_name\": \"OmniSilicon\",\n",
    "            \"entity_type\": \"Company\",\n",
    "            \"entity_description\": \"OmniSilicon is an established competitor in the mobile chip market, now facing direct competition from QuantumChip Inc.\"\n",
    "        }\n",
    "    ],\n",
    "    \"relationships\": [\n",
    "        {\n",
    "            \"source_entity\": \"QuantumChip Inc.\",\n",
    "            \"target_entity\": \"Global Devices Corp.\",\n",
    "            \"relation\": \"IS_SUPPLIER_TO\",\n",
    "            \"relationship_description\": \"The text states that QuantumChip Inc. signed a long-term supply agreement with Global Devices Corp. to provide AI accelerators.\"\n",
    "        },\n",
    "        {\n",
    "            \"source_entity\": \"QuantumChip Inc.\",\n",
    "            \"target_entity\": \"OmniSilicon\",\n",
    "            \"relation\": \"COMPETES_WITH\",\n",
    "            \"relationship_description\": \"The text explicitly states that the deal places QuantumChip in 'direct competition with established player OmniSilicon'.\"\n",
    "        },\n",
    "        {\n",
    "            \"source_entity\": \"Global Devices Corp.\",\n",
    "            \"target_entity\": \"QuantumChip Inc.\",\n",
    "            \"relation\": \"IS_CUSTOMER_OF\",\n",
    "            \"relationship_description\": \"Global Devices Corp. will be using QuantumChip's products in its phones, making it a customer.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    json_pattern = r\"\\{.*\\}\"\n",
    "    match = re.search(json_pattern, response_str, re.DOTALL)\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    if not match:\n",
    "        return entities, relationships\n",
    "    json_str = match.group(0)\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        entities = [\n",
    "            (\n",
    "                entity[\"entity_name\"],\n",
    "                entity[\"entity_type\"],\n",
    "                entity[\"entity_description\"],\n",
    "            )\n",
    "            for entity in data.get(\"entities\", [])\n",
    "        ]\n",
    "        relationships = [\n",
    "            (\n",
    "                relation[\"source_entity\"],\n",
    "                relation[\"target_entity\"],\n",
    "                relation[\"relation\"],\n",
    "                relation[\"relationship_description\"],\n",
    "            )\n",
    "            for relation in data.get(\"relationships\", [])\n",
    "        ]\n",
    "        return entities, relationships\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Setup And Neo4J setup\n",
    "\n",
    "To launch Neo4j locally, first ensure you have docker installed. Then, you can launch the database with the following docker command.\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```\n",
    "From here, you can open the db at http://localhost:7474/. On this page, you will be asked to sign in. Use the default username/password of neo4j and neo4j.\n",
    "\n",
    "Once you login for the first time, you will be asked to change the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = GraphRAGStore(\n",
    "    username=\"neo4j\", password=\"a96534200\", url=\"neo4j://127.0.0.1:7687\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 32/32 [00:38<00:00,  1.20s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityNode(label='Company', embedding=None, properties={'id': 'Ennostar Inc.', 'entity_description': 'Ennostar Inc. is a leader in MicroLED technology, formed by the merger of Epistar and Lextar. The company focuses on advancements in MicroLED modules that offer superior brightness, contrast, and efficiency, targeting next-generation display applications.', 'industry': 'semiconductor', 'triplet_source_id': '71d78798-9112-4596-8706-d186333f6bcc'}, name='Ennostar Inc.'),\n",
       " Relation(label='IS_PARTNER_OF', source_id='Ennostar Inc.', target_id='Novatek Microelectronics', properties={'industry': 'semiconductor', 'triplet_source_id': '71d78798-9112-4596-8706-d186333f6bcc', 'relationship_description': 'Ennostar Inc. is working closely with Novatek Microelectronics to accelerate the commercialization of next-generation displays by combining MicroLED technology with advanced driver IC solutions.'}),\n",
       " EntityNode(label='Company', embedding=None, properties={'id': 'Novatek Microelectronics', 'entity_description': 'Novatek Microelectronics is a leading provider of display driver IC (DDI) and System-on-Chip (SoC) solutions, specializing in sophisticated Touch and Display Driver Integration (TDDI) ICs for automotive-grade applications requiring high reliability and performance.', 'industry': 'semiconductor', 'triplet_source_id': '71d78798-9112-4596-8706-d186333f6bcc'}, name='Novatek Microelectronics')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Ennostar Inc.',\n",
       " 'entity_description': 'Ennostar Inc. is a leader in MicroLED technology, formed by the merger of Epistar and Lextar. The company focuses on advancements in MicroLED modules that offer superior brightness, contrast, and efficiency, targeting next-generation display applications.',\n",
       " 'industry': 'semiconductor',\n",
       " 'triplet_source_id': '71d78798-9112-4596-8706-d186333f6bcc'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry': 'semiconductor',\n",
       " 'triplet_source_id': '71d78798-9112-4596-8706-d186333f6bcc',\n",
       " 'relationship_description': 'Ennostar Inc. is working closely with Novatek Microelectronics to accelerate the commercialization of next-generation displays by combining MicroLED technology with advanced driver IC solutions.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][1].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build communities\n",
    "\n",
    "This will create communities and summary for each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building communities based on 'industry' attribute...\n",
      "Successfully built 3 communities based on industry.\n"
     ]
    }
   ],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 實體與社群的對應關係 (Entity Info) ---\n",
      "{'Richtek Technology Corporation': ['semiconductor'], 'Silicon Motion': ['semiconductor'], 'Chunghwa Precision Test Tech': ['semiconductor'], 'United Microelectronics Corporation': ['semiconductor'], 'Vanguard International Semiconductor': ['semiconductor'], 'Novatek Microelectronics': ['semiconductor'], 'Yageo Corporation': ['semiconductor'], 'Powerchip Semiconductor Manufacturing Corp': ['semiconductor'], 'ASE Technology Holding': ['semiconductor'], 'Ennostar Inc.': ['semiconductor'], 'Macronix International': ['semiconductor'], 'GlobalWafers': ['semiconductor'], 'Unimicron Technology Corp.': ['semiconductor'], 'WIN Semiconductors': ['semiconductor'], 'TSMC': ['semiconductor'], 'Winbond Electronics Corporation': ['semiconductor'], 'Nuvoton Technology Corporation': ['semiconductor'], 'MediaTek': ['semiconductor'], 'Andes Technology': ['semiconductor'], 'Himax Technologies': ['semiconductor'], 'Gudeng Precision': ['semiconductor'], 'Powertech Technology Inc.': ['semiconductor'], 'Phison Electronics': ['semiconductor'], 'Realtek Semiconductor': ['semiconductor'], 'ADATA Technology': ['memory component'], 'Apacer Technology': ['memory component'], 'Transcend Information': ['memory component'], 'Team Group': ['memory component'], 'ASUS': ['PC'], 'Gigabyte': ['PC'], 'Acer': ['PC'], 'MSI': ['PC']}\n",
      "\\n==================================================\\n\n",
      "--- 各個社群的摘要 (Community Summaries) ---\n",
      "【社群 ID: semiconductor】\n",
      "# Semiconductor Industry Community Analysis\n",
      "\n",
      "## 1. Overview\n",
      "The semiconductor industry community comprises a network of companies involved in the design, manufacturing, and supply of semiconductor components and technologies. Key players in this community include semiconductor manufacturers, foundries, suppliers of essential components, and companies specializing in advanced technologies like power management ICs, SSD controllers, and memory solutions.\n",
      "\n",
      "## 2. Key Players\n",
      "- TSMC (Taiwan Semiconductor Manufacturing Company)\n",
      "- MediaTek\n",
      "- Nuvoton Technology Corporation\n",
      "- Novatek Microelectronics\n",
      "- Vanguard International Semiconductor\n",
      "\n",
      "## 3. Relationship Analysis\n",
      "\n",
      "### Competitive Landscape\n",
      "- **TSMC vs. GlobalWafers:** GlobalWafers is expanding its US plant to supply critical silicon wafers to TSMC, supporting TSMC's advanced node production and semiconductor manufacturing needs.\n",
      "\n",
      "### Supply Chain & Partnerships\n",
      "- **TSMC & Chunghwa Precision Test Tech:** Chunghwa Precision Test Tech is a key partner for TSMC, providing advanced probe cards essential for testing TSMC's next-generation AI, HPC, and 5G chips.\n",
      "- **UMC & Nuvoton Technology Corporation:** UMC is expanding its specialty process capacity to support Nuvoton's growth by providing foundry manufacturing services critical for Nuvoton's MCU production.\n",
      "- **WIN Semiconductors & MediaTek:** WIN Semiconductors provides its advanced GaN-on-SiC foundry process to MediaTek for manufacturing high-performance RFICs used in MediaTek's next-generation satellite communication technologies.\n",
      "\n",
      "## 4. Key Insights\n",
      "The semiconductor industry community is characterized by intricate supplier-client relationships and strategic partnerships aimed at driving innovation and meeting the growing demand for advanced semiconductor solutions. Companies like TSMC play a central role in providing manufacturing services to key players such as MediaTek, enabling the development of cutting-edge technologies like AI-enhanced mobile chipsets and high-performance RFICs. Collaboration and specialization within this community are essential for advancing semiconductor technologies and meeting the diverse needs of industries ranging from automotive to networking and multimedia.\n",
      "--------------------\n",
      "【社群 ID: memory component】\n",
      "# Storage Technology Industry Community Analysis\n",
      "\n",
      "## 1. Overview\n",
      "The storage technology industry community is characterized by intense competition and innovation among key players such as ADATA Technology, Transcend Information, Team Group, and Apacer Technology. These companies are engaged in rivalries over next-generation SSDs, DDR5 memory, and industrial-grade storage solutions, targeting high-performance and edge computing markets.\n",
      "\n",
      "## 2. Key Players\n",
      "- ADATA Technology\n",
      "- Transcend Information\n",
      "- Team Group\n",
      "- Apacer Technology\n",
      "\n",
      "## 3. Relationship Analysis\n",
      "\n",
      "### Competitive Landscape\n",
      "- **ADATA Technology -> Transcend Information**\n",
      "  - **Relation:** COMPETES_WITH\n",
      "  - **Relationship Description:** ADATA Technology and Transcend Information are intensifying their long-standing rivalry with the launch of next-generation PCIe 5.0 SSDs, competing for dominance in the high-performance storage market.\n",
      "  \n",
      "- **ADATA Technology -> Team Group**\n",
      "  - **Relation:** COMPETES_WITH\n",
      "  - **Relationship Description:** There is an ongoing innovation race and rivalry between Team Group and ADATA Technology in the high-performance DDR5 memory and SSD market targeting gamers and creators.\n",
      "  \n",
      "- **Apacer Technology -> Transcend Information**\n",
      "  - **Relation:** COMPETES_WITH\n",
      "  - **Relationship Description:** Apacer Technology and Transcend Information are both strengthening their industrial-grade memory and storage offerings for edge computing, indicating direct competition in this market segment.\n",
      "\n",
      "### Supply Chain & Partnerships\n",
      "- No relevant relationships found in the provided data.\n",
      "\n",
      "## 4. Key Insights\n",
      "The storage technology industry community is marked by fierce competition and innovation, particularly in the high-performance storage and memory markets. Companies like ADATA Technology, Transcend Information, Team Group, and Apacer Technology are continuously striving to outperform each other by launching cutting-edge products to cater to the needs of gamers, creators, and industrial users. The focus on next-generation technologies like PCIe 5.0 SSDs and DDR5 memory underscores the industry's commitment to pushing boundaries and meeting the growing demands of various market segments.\n",
      "--------------------\n",
      "【社群 ID: PC】\n",
      "# Consumer Electronics Industry Community Analysis\n",
      "\n",
      "## 1. Overview\n",
      "The consumer electronics industry community is characterized by intense rivalries and direct competition among key players such as ASUS, Gigabyte, Acer, and MSI. These companies compete in various product segments like laptops, displays, motherboards, graphics cards, and gaming products, aiming to capture market share and lead in innovation, particularly in AI-ready hardware and high-performance computing.\n",
      "\n",
      "## 2. Key Players\n",
      "- ASUS\n",
      "- Gigabyte\n",
      "- Acer\n",
      "- MSI\n",
      "\n",
      "## 3. Relationship Analysis\n",
      "\n",
      "### Competitive Landscape\n",
      "- **ASUS -> Gigabyte -> COMPETES_WITH:** ASUS and Gigabyte intensify their rivalry in AI-ready hardware, including motherboards, graphics cards, laptops, and servers.\n",
      "- **ASUS -> Acer -> COMPETES_WITH:** Acer and ASUS compete directly in laptops, displays, and gaming products to gain market share in the consumer electronics industry.\n",
      "- **Gigabyte -> ASUS -> COMPETES_WITH:** ASUS and Gigabyte have a long-standing rivalry in AI-ready hardware, motherboards, graphics cards, laptops, and servers.\n",
      "- **Gigabyte -> MSI -> COMPETES_WITH:** Gigabyte and MSI fiercely compete in motherboards and graphics cards, targeting PC enthusiasts and gamers.\n",
      "- **Acer -> ASUS -> COMPETES_WITH:** Acer and ASUS are long-standing rivals in laptops, displays, and gaming products, striving for a larger market share in consumer electronics.\n",
      "\n",
      "### Supply Chain & Partnerships\n",
      "(N/A)\n",
      "\n",
      "## 4. Key Insights\n",
      "The consumer electronics industry community is marked by intense competition and rivalry among key players like ASUS, Gigabyte, Acer, and MSI. These companies are focused on innovation and product development in various segments to cater to consumer demands. The emphasis on AI-ready hardware, high-performance computing, and gaming products underscores the industry's drive for technological advancement and market leadership.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 獲取已經建立好社群的 graph_store 物件\n",
    "graph_store_with_communities = index.property_graph_store\n",
    "\n",
    "# 1. 查看每個實體 (公司) 分別屬於哪些社群\n",
    "#    格式為 { '公司名稱': [社群ID_1, 社群ID_2, ...] }\n",
    "print(\"--- 實體與社群的對應關係 (Entity Info) ---\")\n",
    "print(graph_store_with_communities.entity_info)\n",
    "print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "\n",
    "# 2. 查看每個社群的文字摘要\n",
    "#    格式為 { 社群ID: '這個社群的摘要文字...' }\n",
    "print(\"--- 各個社群的摘要 (Community Summaries) ---\")\n",
    "for community_id, summary in graph_store_with_communities.community_summary.items():\n",
    "    print(f\"【社群 ID: {community_id}】\")\n",
    "    print(summary)\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create QueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store,\n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['MediaTek']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided information, MediaTek has five relationships: partners with ASE Technology Holding and Andes Technology (2 relationships), and suppliers including Richtek Technology Corporation, Yageo Corporation, and Andes Technology (3 relationships). Andes Technology appears as both a partner and a supplier, representing two distinct relationship types."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"In total, how many relationship MediaTek have?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['TSMC']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the community summary, TSMC has at least seven distinct relationships: three with suppliers (GlobalWafers, Unimicron Technology Corp., Gudeng Precision), two with customers (Phison Electronics, Silicon Motion), and two with customers/partners (MediaTek, Realtek Semiconductor)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"In total, how many relationship TSMC have?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['ASUS']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the community summary, ASUS is involved in a total of 4 competitive relationships: ASUS competes with Gigabyte and Acer, and both Gigabyte and Acer compete with ASUS."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"In total, how many relationship ASUS have?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['MediaTek']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "MediaTek maintains key relationships with partners like ASE Technology Holding for packaging solutions and Andes Technology for CPU cores, enabling advanced integration in its system-on-chips (SoCs). It also relies on suppliers such as Richtek Technology Corporation, Yageo Corporation, and Andes Technology for essential components in its SoCs and RFICs. These collaborations support MediaTek’s innovation and technological advancement, particularly in AI, automotive, and IoT applications. While operating in a competitive semiconductor landscape alongside companies like Realtek Semiconductor and Silicon Motion, MediaTek’s focus remains on strategic partnerships that enhance its product development and manufacturing capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are the key relationships MediaTek has, and what is the nature of these partnerships or competitions?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['TSMC', 'MediaTek']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "MediaTek positions itself as a key semiconductor industry player by leveraging strategic collaborations and a strong supplier network to compete with rivals like Qualcomm. Key partnerships include TSMC for advanced chip manufacturing, ASE Technology Holding for packaging solutions, and Andes Technology for CPU cores. These collaborations grant MediaTek access to cutting-edge fabrication technologies and enhance its product capabilities in AI, automotive, and IoT applications. By integrating these relationships and focusing on innovation, MediaTek emphasizes technological advancement and a robust supply chain to maintain competitiveness in the market."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Based on its relationships, how does MediaTek position itself against competitors like Qualcomm and collaborate with suppliers like TSMC?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entities in query: ['TSMC']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The current trend in the semiconductor industry is marked by increasing collaboration and integration across the supply chain to drive innovation. TSMC’s central role as a leading foundry underscores the industry's focus on advanced manufacturing to support cutting-edge products. Partnerships with companies like MediaTek, Realtek, and Phison highlight a move toward specialization and reliance on expert manufacturing to meet growing demands in AI, automotive, and IoT sectors. Overall, the industry is evolving toward deeper cooperation among suppliers, manufacturers, and customers to accelerate the development and production of sophisticated semiconductor technologies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Based on TSMC's relationships and activities, what is the current trend of the semiconductor industry?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GraphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
