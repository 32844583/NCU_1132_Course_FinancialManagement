{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11920902,"sourceType":"datasetVersion","datasetId":7494540}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 環境與套件準備\n\n此初始階段包含數個步驟，旨在設定執行環境並安裝必要的 Python 套件。\n\n1.  **NVIDIA GPU 檢查**:\n    * 執行 `!nvidia-smi` 指令來確認 NVIDIA GPU 的可用性與狀態，這對於後續需要 GPU 加速的運算（如模型推論、FAISS 索引）至關重要。\n2.  **CUDA 版本確認**:\n    * 透過 `!cat /usr/local/cuda/version.txt` 和 `!ls -l /usr/local | grep cuda` 查看系統中安裝的 CUDA 版本。\n    * 使用 `torch.version.cuda` 和 `torch.backends.cudnn.version()` 經由 PyTorch 函式庫來確認 CUDA 和 cuDNN 的版本，確保與後續安裝的套件相容。\n3.  **安裝核心套件**:\n    * `!pip install faiss-gpu-cu12 --quiet`: 安裝 FAISS 的 GPU 版本 (針對 CUDA 12.x)，FAISS 是由 Facebook AI 開發的高效相似性搜索函式庫，用於處理向量嵌入。`--quiet` 參數表示以靜默模式安裝，減少輸出訊息。\n    * `!pip install langchain-community --quiet`: 安裝 Langchain Community 版本的相關套件。Langchain 是一個用於開發由語言模型驅動的應用程式的框架，它提供了許多模組化的工具來串接不同的元件。","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:13.987133Z","iopub.execute_input":"2025-05-26T02:58:13.987348Z","iopub.status.idle":"2025-05-26T02:58:14.213182Z","shell.execute_reply.started":"2025-05-26T02:58:13.987332Z","shell.execute_reply":"2025-05-26T02:58:14.212309Z"}},"outputs":[{"name":"stdout","text":"Mon May 26 02:58:14 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   48C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   46C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!ls -l /usr/local/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:14.214093Z","iopub.execute_input":"2025-05-26T02:58:14.214323Z","iopub.status.idle":"2025-05-26T02:58:14.338985Z","shell.execute_reply.started":"2025-05-26T02:58:14.214298Z","shell.execute_reply":"2025-05-26T02:58:14.338107Z"}},"outputs":[{"name":"stdout","text":"total 72\ndrwxr-xr-x 1 1000 1000 4096 May  8 12:31 bin\ndrwxr-xr-x 3 root root 4096 Apr  4 13:51 colab\nlrwxrwxrwx 1 root root   22 Jul 10  2024 cuda -> /etc/alternatives/cuda\nlrwxrwxrwx 1 root root   25 Jul 10  2024 cuda-12 -> /etc/alternatives/cuda-12\ndrwxr-xr-x 1 root root 4096 Jul 10  2024 cuda-12.5\n-rw-r--r-- 1 root root 2626 Apr  4 13:38 dist_metrics.pxd\ndrwxr-xr-x 3 root root 4096 May  8 12:26 doc\ndrwxr-xr-x 1 1000 1000 4096 Apr  4 13:45 etc\ndrwxr-xr-x 2 root root 4096 Jun 27  2024 games\ndrwxr-xr-x 2 root root 4096 May  8 12:26 images\ndrwxr-xr-x 1 1000 1000 4096 Apr  4 13:45 include\ndrwxr-xr-x 1 1000 1000 4096 May  8 12:28 lib\ndrwxr-xr-x 3 1000 1000 4096 Mar 10 13:23 libexec\n-rw-r--r-- 1 1000 1000 1321 Mar 10 13:23 LICENSE.md\nlrwxrwxrwx 1 root root    9 Jun 27  2024 man -> share/man\ndrwxr-xr-x 3 root root 4096 May 26 02:57 nvidia\ndrwxr-xr-x 1 root root 4096 Apr  4 13:45 opt\ndrwxr-xr-x 2 root root 4096 Jun 27  2024 sbin\ndrwxr-xr-x 1 1000 1000 4096 Apr  4 13:45 share\ndrwxr-xr-x 2 root root 4096 Jun 27  2024 src\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!cat /usr/local/cuda/version.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:14.341154Z","iopub.execute_input":"2025-05-26T02:58:14.341394Z","iopub.status.idle":"2025-05-26T02:58:14.460477Z","shell.execute_reply.started":"2025-05-26T02:58:14.341372Z","shell.execute_reply":"2025-05-26T02:58:14.459620Z"}},"outputs":[{"name":"stdout","text":"cat: /usr/local/cuda/version.txt: No such file or directory\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!ls -l /usr/local | grep cuda","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:14.461418Z","iopub.execute_input":"2025-05-26T02:58:14.461603Z","iopub.status.idle":"2025-05-26T02:58:14.587651Z","shell.execute_reply.started":"2025-05-26T02:58:14.461582Z","shell.execute_reply":"2025-05-26T02:58:14.586903Z"}},"outputs":[{"name":"stdout","text":"lrwxrwxrwx 1 root root   22 Jul 10  2024 cuda -> /etc/alternatives/cuda\nlrwxrwxrwx 1 root root   25 Jul 10  2024 cuda-12 -> /etc/alternatives/cuda-12\ndrwxr-xr-x 1 root root 4096 Jul 10  2024 cuda-12.5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nprint('CUDA:',torch.version.cuda)\n\ncudnn = torch.backends.cudnn.version()\ncudnn_major = cudnn // 1000\ncudnn = cudnn % 1000\ncudnn_minor = cudnn // 100\ncudnn_patch = cudnn % 100\nprint( 'cuDNN:', '.'.join([str(cudnn_major),str(cudnn_minor),str(cudnn_patch)]) )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:14.589088Z","iopub.execute_input":"2025-05-26T02:58:14.589397Z","iopub.status.idle":"2025-05-26T02:58:19.139810Z","shell.execute_reply.started":"2025-05-26T02:58:14.589343Z","shell.execute_reply":"2025-05-26T02:58:19.139233Z"}},"outputs":[{"name":"stdout","text":"CUDA: 12.4\ncuDNN: 90.3.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install faiss-gpu-cu12 --quiet # CUDA 12.x, Python 3.8+\n!pip install langchain-community --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:19.140798Z","iopub.execute_input":"2025-05-26T02:58:19.141135Z","iopub.status.idle":"2025-05-26T02:58:33.796921Z","shell.execute_reply.started":"2025-05-26T02:58:19.141116Z","shell.execute_reply":"2025-05-26T02:58:33.796222Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### 文本切分 (Chunking)\n\n這個階段的目標是將輸入的文本資料（來自指定目錄下的 `.txt` 檔案）讀取並分割成較小的、可管理的文本區塊 (chunks)。這樣做的目的是為了讓後續的嵌入模型能夠更有效地處理文本，並且在進行相似度搜索時，能夠定位到更精確的資訊片段。\n\n主要步驟如下：\n1.  **設定參數**:\n    * `FILES_DIRECTORY`: 指定包含來源 `.txt` 檔案的目錄路徑。\n    * `CHUNK_SIZE`: 設定每個文本區塊的目標大小（以字元數計算）。\n    * `CHUNK_OVERLAP`: 設定連續文本區塊之間的重疊字元數。重疊有助於保持文本的連貫性，避免資訊在切分邊界被切割斷裂。\n    * `LENGTH_FUNCTION`: 指定計算文本長度的函式 (在此使用 `len`)。\n2.  **初始化文本分割器**:\n    * 使用 `langchain.text_splitter.RecursiveCharacterTextSplitter` 初始化一個文本分割器物件。此分割器會嘗試依據預設的分隔符號（如換行符、空格等）遞迴地分割文本，直到達到指定的 `CHUNK_SIZE`。\n3.  **遍歷與處理檔案**:\n    * 使用 `os.listdir` 列出指定目錄下的所有檔案和子目錄。\n    * 對於每個項目，檢查其是否為 `.txt` 結尾的檔案。\n    * 若是文本檔案，則以 `utf-8` 編碼讀取其內容。\n    * 使用先前初始化的 `text_splitter` 將檔案內容分割成多個文本區塊。\n    * 將處理好的文本區塊及其來源檔案名稱分別儲存到 `all_processed_chunks` 和 `all_source_file_names` 列表中。\n4.  **結果檢視**:\n    * 印出總共生成的文本區塊數量。\n    * 如果生成了文本區塊，則顯示前幾個區塊的內容及其來源檔案，作為處理結果的範例。\n5.  **變數指派**:\n    * 將 `all_processed_chunks` 和 `all_source_file_names` 的內容指派給 `all_chunks` 和 `all_file_names`，以供後續儲存格使用。","metadata":{}},{"cell_type":"code","source":"import os\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nFILES_DIRECTORY = '/kaggle/input/company/' # 指定包含 .txt 文件的目錄路徑\nCHUNK_SIZE = 1000      # 每個文本區塊的目標大小 (字元數)\nCHUNK_OVERLAP = 200    # 連續區塊之間的重疊字元數\nLENGTH_FUNCTION = len  # 用於計算文本長度的函式\nDISPLAY_SAMPLE_COUNT = 5 # 處理完成後顯示的區塊範例數量\n\nprint(f\"Initializing text processing for directory: {FILES_DIRECTORY}\")\n\nprint(\"Initializing RecursiveCharacterTextSplitter...\")\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=CHUNK_SIZE,\n    chunk_overlap=CHUNK_OVERLAP,\n    length_function=LENGTH_FUNCTION,\n    is_separator_regex=False, # 如果分隔符是正則表達式，則設為 True\n)\n\nall_processed_chunks = []\nall_source_file_names = []\n\nprint(f\"\\nStarting to process files in: {FILES_DIRECTORY}...\")\n\ntry:\n    file_list = os.listdir(FILES_DIRECTORY)\n    print(f\"Files and directories found: {file_list if file_list else 'None'}\")\nexcept FileNotFoundError:\n    print(f\"❌ ERROR: Directory not found at '{FILES_DIRECTORY}'. Please verify the path.\")\n    file_list = []\n\nfor item_name in file_list:\n    file_path = os.path.join(FILES_DIRECTORY, item_name)\n    \n    if item_name.endswith(\".txt\") and os.path.isfile(file_path):\n        print(f\"\\nProcessing text file: {item_name} (Path: {file_path})\")\n        \n        try:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                text_content = file.read()\n            print(f\"  Successfully loaded content from {item_name} (Length: {len(text_content)} chars).\")\n\n            print(f\"  Splitting document '{item_name}' into chunks...\")\n            current_file_chunks = text_splitter.split_text(text_content)\n            \n            all_processed_chunks.extend(current_file_chunks)\n            all_source_file_names.extend([item_name] * len(current_file_chunks))\n            \n            print(f\"  Document '{item_name}' split into {len(current_file_chunks)} chunks.\")\n            print(f\"  Total chunks collected so far: {len(all_processed_chunks)}\")\n            \n        except Exception as e:\n            print(f\"  ❌ ERROR processing file {item_name}: {e}\")\n            \n    elif os.path.isdir(file_path):\n        print(f\"  Skipping directory: {item_name}\")\n    else:\n        print(f\"  Skipping non-txt file or unrecognized item: {item_name}\")\n\nprint(\"\\n---\")\nprint(f\"✅ All files in '{FILES_DIRECTORY}' processed.\")\nprint(f\"Total text chunks generated: {len(all_processed_chunks)}\")\nprint(f\"Total source file name entries: {len(all_source_file_names)}\")\n\nif all_processed_chunks:\n    print(f\"\\n--- Displaying first {min(DISPLAY_SAMPLE_COUNT, len(all_processed_chunks))} generated chunks ---\")\n    for i in range(min(DISPLAY_SAMPLE_COUNT, len(all_processed_chunks))):\n        print(f\"\\nSample Chunk {i+1} (from file: {all_source_file_names[i]}):\")\n        print(all_processed_chunks[i])\n        print(\"---\")\nelse:\n    print(\"\\nNo text chunks were generated. Please check input files and directory.\")\n\nprint(\"\\nText loading and chunking process for multiple files complete.\")\n\n# 確保後續儲存格可以使用原始筆記本期望的變數名稱\nall_chunks = all_processed_chunks\nall_file_names = all_source_file_names\nprint(f\"\\nVariables 'all_chunks' ({len(all_chunks)} items) and 'all_file_names' ({len(all_file_names)} items) are now available for subsequent cells.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:33.797975Z","iopub.execute_input":"2025-05-26T02:58:33.798220Z","iopub.status.idle":"2025-05-26T02:58:34.377482Z","shell.execute_reply.started":"2025-05-26T02:58:33.798191Z","shell.execute_reply":"2025-05-26T02:58:34.376805Z"}},"outputs":[{"name":"stdout","text":"Initializing text processing for directory: /kaggle/input/company/\nInitializing RecursiveCharacterTextSplitter...\n\nStarting to process files in: /kaggle/input/company/...\nFiles and directories found: ['(MediaTek) .txt', '(ASE Technology Holding).txt', '(GUC).txt', '(TSMC).txt', '(ASMedia).txt', '(Winbond).txt', '(KYEC).txt', '(Realtek).txt', '(UMC).txt', '(Novatek).txt', '(Nanya Technology).txt']\n\nProcessing text file: (MediaTek) .txt (Path: /kaggle/input/company/(MediaTek) .txt)\n  Successfully loaded content from (MediaTek) .txt (Length: 2914 chars).\n  Splitting document '(MediaTek) .txt' into chunks...\n  Document '(MediaTek) .txt' split into 4 chunks.\n  Total chunks collected so far: 4\n\nProcessing text file: (ASE Technology Holding).txt (Path: /kaggle/input/company/(ASE Technology Holding).txt)\n  Successfully loaded content from (ASE Technology Holding).txt (Length: 1635 chars).\n  Splitting document '(ASE Technology Holding).txt' into chunks...\n  Document '(ASE Technology Holding).txt' split into 2 chunks.\n  Total chunks collected so far: 6\n\nProcessing text file: (GUC).txt (Path: /kaggle/input/company/(GUC).txt)\n  Successfully loaded content from (GUC).txt (Length: 3175 chars).\n  Splitting document '(GUC).txt' into chunks...\n  Document '(GUC).txt' split into 4 chunks.\n  Total chunks collected so far: 10\n\nProcessing text file: (TSMC).txt (Path: /kaggle/input/company/(TSMC).txt)\n  Successfully loaded content from (TSMC).txt (Length: 2648 chars).\n  Splitting document '(TSMC).txt' into chunks...\n  Document '(TSMC).txt' split into 4 chunks.\n  Total chunks collected so far: 14\n\nProcessing text file: (ASMedia).txt (Path: /kaggle/input/company/(ASMedia).txt)\n  Successfully loaded content from (ASMedia).txt (Length: 3290 chars).\n  Splitting document '(ASMedia).txt' into chunks...\n  Document '(ASMedia).txt' split into 5 chunks.\n  Total chunks collected so far: 19\n\nProcessing text file: (Winbond).txt (Path: /kaggle/input/company/(Winbond).txt)\n  Successfully loaded content from (Winbond).txt (Length: 1651 chars).\n  Splitting document '(Winbond).txt' into chunks...\n  Document '(Winbond).txt' split into 2 chunks.\n  Total chunks collected so far: 21\n\nProcessing text file: (KYEC).txt (Path: /kaggle/input/company/(KYEC).txt)\n  Successfully loaded content from (KYEC).txt (Length: 3508 chars).\n  Splitting document '(KYEC).txt' into chunks...\n  Document '(KYEC).txt' split into 5 chunks.\n  Total chunks collected so far: 26\n\nProcessing text file: (Realtek).txt (Path: /kaggle/input/company/(Realtek).txt)\n  Successfully loaded content from (Realtek).txt (Length: 3012 chars).\n  Splitting document '(Realtek).txt' into chunks...\n  Document '(Realtek).txt' split into 4 chunks.\n  Total chunks collected so far: 30\n\nProcessing text file: (UMC).txt (Path: /kaggle/input/company/(UMC).txt)\n  Successfully loaded content from (UMC).txt (Length: 2799 chars).\n  Splitting document '(UMC).txt' into chunks...\n  Document '(UMC).txt' split into 4 chunks.\n  Total chunks collected so far: 34\n\nProcessing text file: (Novatek).txt (Path: /kaggle/input/company/(Novatek).txt)\n  Successfully loaded content from (Novatek).txt (Length: 3124 chars).\n  Splitting document '(Novatek).txt' into chunks...\n  Document '(Novatek).txt' split into 4 chunks.\n  Total chunks collected so far: 38\n\nProcessing text file: (Nanya Technology).txt (Path: /kaggle/input/company/(Nanya Technology).txt)\n  Successfully loaded content from (Nanya Technology).txt (Length: 3453 chars).\n  Splitting document '(Nanya Technology).txt' into chunks...\n  Document '(Nanya Technology).txt' split into 5 chunks.\n  Total chunks collected so far: 43\n\n---\n✅ All files in '/kaggle/input/company/' processed.\nTotal text chunks generated: 43\nTotal source file name entries: 43\n\n--- Displaying first 5 generated chunks ---\n\nSample Chunk 1 (from file: (MediaTek) .txt):\n聯發科 (MediaTek) 公司概覽與市場地位 (截至 2025/5/23)\n聯發科技股份有限公司 (聯發科，MediaTek) 是全球頂尖的無晶圓廠半導體公司，專注於設計各種系統單晶片 (SoC) 解決方案，在全球消費性電子、通訊及人工智慧 (AI) 領域扮演著舉足輕重的角色。\n\n公司簡介：\n\n聯發科成立於 1997年5月28日，由聯華電子 (UMC) 的多媒體部門分拆獨立而成。其主要業務為積體電路 (IC) 設計，核心產品與服務是為各種智能設備提供高效能、低功耗的系統單晶片 (SoC) 及相關解決方案。這包括行動通訊處理器 (如天璣系列)、智慧家庭晶片 (電視、路由器、智慧音箱等)、無線連接技術晶片 (Wi-Fi, 藍牙等)、物聯網 (IoT) 晶片以及電源管理IC等。公司總部位於台灣新竹科學園區。\n\n半導體產業鏈中的角色：\n\n聯發科在半導體產業鏈中扮演IC 設計公司的角色。作為一家無晶圓廠 (Fabless) 的半導體公司，聯發科專注於晶片的研發、設計和行銷，而將晶片的製造、封裝和測試等環節委託給專業的晶圓代工廠 (如台積電) 和封裝測試廠。聯發科憑藉其創新的設計能力，在全球行動通訊、智慧家庭及物聯網等領域提供具競爭力的晶片解決方案。\n\n主要產品應用終端市場：\n\n聯發科的晶片被廣泛應用於多元的終端市場，主要包括：\n\n智慧型手機：這是聯發科最主要的營收來源之一，其天璣 (Dimensity) 系列行動處理器廣泛應用於從旗艦到主流的各類智慧型手機。\n智慧家庭/智能設備：包括智慧電視、路由器、智慧音箱、串流裝置、平板電腦、Chromebook 等。\n無線連接產品：提供 Wi-Fi、藍牙等無線通訊晶片。\n物聯網 (IoT)：應用於穿戴式裝置、工業控制、智慧零售、健康醫療等多種物聯網設備。\n汽車電子：近年來積極投入，提供智慧座艙、車載資通訊系統等相關晶片解決方案。\n個人AI電腦與數據中心/企業級AI：作為新興的拓展領域，聯發科正積極佈局客製化AI加速器等產品。\n主要客戶群體：\n\n聯發科的客戶群體主要是全球各大終端產品品牌商和原始設計製造商 (ODM)。雖然聯發科通常不公開其具體客戶名單，但其客戶主要屬於以下產業或類型：\n---\n\nSample Chunk 2 (from file: (MediaTek) .txt):\n聯發科的客戶群體主要是全球各大終端產品品牌商和原始設計製造商 (ODM)。雖然聯發科通常不公開其具體客戶名單，但其客戶主要屬於以下產業或類型：\n\n智慧型手機品牌商：涵蓋全球多個主要的手機製造商。\n消費性電子產品製造商：生產智慧電視、平板電腦、路由器、智慧音箱、穿戴裝置等的廠商。\n物聯網設備開發商：涵蓋工業、零售、醫療等多元領域。\n汽車零組件供應商及汽車製造商：在智慧汽車領域的合作夥伴。\n雲端服務供應商及企業客戶：在客製化AI晶片領域的潛在及現有客戶。\n主要營收來源：\n\n聯發科的營收主要來自其各類晶片產品的銷售。根據近期（截至2024年底及2025年第一季）的公開資訊，其主要營收來源大致如下：\n\n行動通訊 (Mobile Phone)：主要為智慧型手機處理器等。在2025年第一季，此部分約佔總營收的 56%。\n智慧終端平台 (Smart Edge Platforms)：此類別涵蓋智慧家庭（如電視、路由器）、平板電腦、Chromebook、物聯網、ASIC（客製化晶片）、車用電子等。在2025年第一季，此部分約佔總營收的 38%。\n電源管理IC (Power IC)：約佔總營收的 6% (2025年第一季數據)。\n具體各產品線的營收佔比會因市場需求、新產品週期及季節性因素而有所波動。近年來，除了穩固其在智慧型手機市場的地位外，聯發科也積極拓展在智慧物聯網、汽車電子以及AI相關領域的市場，以實現營收來源的多元化。\n\n一、 最近期財報表現 (2025年第一季)\n\n聯發科最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現穩健：\n\n營收：新台幣 1355 億元（年增約 32%，季減約 8%）。\n毛利率：48.5%（符合公司預期，年增0.5個百分點）。\n營業利益率：18.2%。\n每股盈餘 (EPS)：約為新台幣 19.85 元。\n公司指出，2025年第一季營收表現主要受惠於手機客戶庫存回補以及旗艦手機晶片（如天璣9400系列）出貨暢旺。智慧裝置平台（Smart Edge Platform）業務也維持成長動能。\n\n二、 市場分析與公司未來展望\n---\n\nSample Chunk 3 (from file: (MediaTek) .txt):\n二、 市場分析與公司未來展望\n\n市場分析師普遍看好聯發科在手機市場，特別是旗艦級SoC（系統單晶片）的競爭力，並預期AI在終端裝置的滲透將為其帶來新的成長機會。此外，公司在Wi-Fi 7、車用電子、電源管理IC（PMIC）等領域的拓展也受到關注。\n\n聯發科管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：\n\n2025年第二季財務預測：\n營收預計介於新台幣 1420 億元至 1508 億元之間（預期季增約5%至11%）。\n毛利率預計介於 47.5% 至 49.5% 之間（中位數為48.5%）。\n2025年全年展望：\n公司預期2025年全年美元營收將實現中雙位數（mid-teens，約14-16%）的年成長。\n手機業務預計將有顯著成長，主要由旗艦和高階市場的市佔率提升及規格升級帶動。\n智慧裝置平台業務（包括電視晶片、Wi-Fi、ASIC、車用等）預期也將持續成長。\nAI將是重要成長催化劑，無論是手機SoC整合的AI處理單元，或是針對邊緣運算裝置的AI晶片。\n分析師認為，聯發科的天璣系列處理器在效能與功耗上已具備與主要競爭對手抗衡的實力，有助於其在高階市場持續擴大份額。\n\n三、 影響營運的主要正面與負面因素\n\n綜合來看，影響聯發科近期財務表現及未來展望的因素如下：\n\n主要正面因素：\n\n旗艦手機晶片強勁：天璣系列（如天璣9400及後續產品）在效能、AI運算能力及功耗上的競爭力，帶動高階手機市場的市佔率提升和平均售價(ASP)上揚。\nAI技術整合與邊緣AI商機：AI在手機、IoT裝置、汽車等邊緣運算平台的應用，為聯發科的晶片帶來新的需求與價值。\n多元化產品組合：在智慧裝置平台業務，如Wi-Fi 7晶片、電視SoC、ASIC（客製化晶片）、車用電子、電源管理IC等領域的持續成長，降低對單一市場的依賴。\n市場庫存健康：經過調整後，手機供應鏈庫存回到健康水位，有利於訂單穩定。\n中國市場復甦與升級：中國手機市場若持續復甦並朝向規格升級，將有利於聯發科的出貨。\n主要負面因素與挑戰：\n---\n\nSample Chunk 4 (from file: (MediaTek) .txt):\n全球宏觀經濟不確定性：全球經濟成長放緩、通膨壓力等因素可能影響消費性電子產品的整體需求。\n市場競爭激烈：手機晶片市場競爭依然激烈，主要競爭對手（如高通）亦持續推出新品，且部分手機品牌廠亦有自研晶片的趨勢。\n地緣政治風險：國際貿易情勢的變化可能對供應鏈及市場需求帶來不確定性。\n消費性電子需求波動：智慧型手機等消費性電子產品的需求易受景氣循環影響，若市場復甦力道不如預期，可能影響出貨。\n新業務拓展的執行風險：雖然車用、ASIC等新業務具成長潛力，但市場拓展和技術研發仍需持續投入並面對執行上的挑戰。\n整體而言，聯發科憑藉其在手機晶片市場的技術實力以及在AI和多元化業務的佈局，市場對其2025年的成長前景抱持正面看法，但仍需關注全球經濟及產業競爭的動態。\n---\n\nSample Chunk 5 (from file: (ASE Technology Holding).txt):\n日月光投控 (ASE Technology Holding) 公司概覽與市場地位 (截至 2025/5/23)\n日月光投資控股股份有限公司 (日月光投控，ASE Technology Holding) 是全球半導體封裝測試與電子代工服務的領導廠商，由日月光半導體製造股份有限公司 (ASE) 與矽品精密工業股份有限公司 (SPIL) 於 2018年4月30日結合成立（日月光本身成立於1984年）。公司致力於提供完整的半導體後段製造服務及電子製造解決方案。\n\n公司簡介：\n\n日月光投控的主要業務涵蓋兩大領域：半導體封裝與測試 (ATM - Assembly, Test, Materials) 以及電子代工服務 (EMS)。核心產品與服務包括：\n\n半導體封裝與測試：提供各種積體電路 (IC) 的封裝服務（如傳統打線封裝、覆晶封裝、晶圓級封裝 (WLP)、系統級封裝 (SiP)、2.5D/3D 封裝等先進封裝技術）、晶圓針測、成品測試以及互連材料的設計與生產。\n電子代工服務 (EMS)：透過子公司環旭電子 (USI)，提供通訊類、消費電子類、電腦類、存儲類、工業類、汽車電子類等產品的開發設計、物料採購、生產製造、物流及售後服務。\n公司總部位於台灣高雄。\n\n半導體產業鏈中的角色：\n\n日月光投控在半導體產業鏈中扮演著關鍵的封裝測試 (OSAT - Outsourced Semiconductor Assembly and Test) 角色，是全球規模最大的專業封測廠。此外，透過其EMS業務，也參與了下游的電子產品製造環節。公司提供從晶圓後段製程到系統組裝的一站式服務。\n\n主要產品應用終端市場：\n\n日月光投控的服務與產品廣泛應用於各種終端市場，主要包括：\n\n通訊：智慧型手機、網通設備等。\n高效能運算 (HPC) 與人工智慧 (AI)：伺服器、AI 加速晶片等。\n電腦：個人電腦、筆記型電腦及其周邊。\n汽車電子：車用處理器、感測器、電源管理IC、車載資通訊系統等。\n消費性電子：智慧穿戴裝置、遊戲機、物聯網設備、AR/VR 裝置等。\n工業控制：工業自動化設備等。\n主要客戶群體：\n\n日月光投控的客戶群體遍及全球，主要包括：\n---\n\nText loading and chunking process for multiple files complete.\n\nVariables 'all_chunks' (43 items) and 'all_file_names' (43 items) are now available for subsequent cells.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 文本嵌入 (Embedding)\n\n在文本被切分成較小的區塊後，下一個關鍵步驟是將這些文本區塊轉換成數值向量，這個過程稱為「嵌入」(Embedding)。嵌入向量能夠在多維空間中表示文本的語義意義，使得語義上相似的文本在向量空間中也更為接近。\n\n此階段的流程：\n1.  **載入預訓練模型**:\n    * 從 `sentence_transformers` 函式庫載入一個預訓練的句子轉換器模型。筆記本中指定使用 `infgrad/stella-large-zh-v2` 模型，這是一個針對繁體中文進行優化的模型，能將中文文本轉換為高品質的嵌入向量。\n2.  **生成嵌入向量**:\n    * 使用載入的 `embedding_model_stella` 對前一階段產生的所有文本區塊 (`all_chunks`) 進行編碼。\n    * `encode()` 方法會為每個文本區塊生成一個固定維度的數值向量（嵌入）。\n    * 設定 `show_progress_bar=True` 以在編碼過程中顯示進度。\n3.  **結果驗證與檢視**:\n    * 印出成功生成嵌入向量的訊息，以及嵌入向量矩陣的形狀 (shape)，通常是 (文本區塊數量, 嵌入向量維度)。\n    * 如果成功生成，則展示第一個文本區塊對應的嵌入向量作為範例。","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nprint(\"Loading sentence-transformers model: infgrad/stella-large-zh-v2...\")\nmodel_name_stella = 'infgrad/stella-large-zh-v2' # 用於嵌入的句子轉換器模型ID\nembedding_model_stella = SentenceTransformer(model_name_stella) # 已初始化的句子轉換器模型\nprint(f\"Model {model_name_stella} loaded successfully.\")\n\nprint(\"Generating embeddings for all chunks using stella-large-zh-v2...\")\nall_chunk_embeddings = embedding_model_stella.encode(\n    all_chunks, # 來自前一階段的文本區塊列表\n    show_progress_bar=True # 編碼時顯示進度條\n)\n\nprint(f\"Embeddings generated successfully. Shape of embeddings: {all_chunk_embeddings.shape}\")\n\nif 'all_chunks' in locals() and len(all_chunks) > 0 and hasattr(all_chunk_embeddings, 'shape') and all_chunk_embeddings.shape[0] > 0:\n    print(\"Example of the first chunk's embedding:\")\n    print(all_chunk_embeddings[0])\nelse:\n    print(\"No chunks were provided or embeddings could not be generated to display an example.\")\n\nprint(\"Text embedding process with infgrad/stella-large-zh-v2 complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:58:34.378249Z","iopub.execute_input":"2025-05-26T02:58:34.378548Z","iopub.status.idle":"2025-05-26T02:59:13.961334Z","shell.execute_reply.started":"2025-05-26T02:58:34.378520Z","shell.execute_reply":"2025-05-26T02:59:13.960335Z"}},"outputs":[{"name":"stderr","text":"2025-05-26 02:58:43.647525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748228323.836095      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748228323.889375      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading sentence-transformers model: infgrad/stella-large-zh-v2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72f46b60514b42f98dbfe89baf26d3da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/652M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91412a78331944c5bc9fbbd68d3b46c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/652M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197360f2eb8d42da98911279aefe0d84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/315 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55ff4579f9440dd879747ba956bf7f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e55642a8b1a4439a7ce8f23f44a5068"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/439k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1cd7df858ba4540bc7381cab33691d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ce4c4cd51b4b11ac9272762e04dc2a"}},"metadata":{}},{"name":"stdout","text":"Model infgrad/stella-large-zh-v2 loaded successfully.\nGenerating embeddings for all chunks using stella-large-zh-v2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d989ddc25d3438baa087068e9afe262"}},"metadata":{}},{"name":"stdout","text":"Embeddings generated successfully. Shape of embeddings: (43, 1024)\nExample of the first chunk's embedding:\n[-0.35826454 -0.52658534 -1.737512   ... -1.9845805   1.4106016\n  0.08923372]\nText embedding process with infgrad/stella-large-zh-v2 complete.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 向量索引 (Vector Indexing)\n\n獲得文本區塊的嵌入向量後，為了能夠快速地根據查詢向量找到最相似的文本區塊向量，我們需要建立一個向量索引。FAISS (Facebook AI Similarity Search) 是一個高效能的函式庫，專門用於大規模向量的相似性搜索和聚類。\n\n此階段的步驟：\n1.  **導入函式庫與檢查嵌入向量**:\n    * 導入 `faiss` 和 `numpy` 函式庫。\n    * 檢查 `all_chunk_embeddings` 是否存在且不為 None。如果不存在（例如，前一步驟執行失敗），則會創建一個隨機的虛擬數據用於後續測試，並給出提示。\n    * 確認嵌入向量的數據類型。FAISS 通常期望輸入為 `float32` 型別的向量，如果不是，則進行轉換。\n    * 檢查嵌入向量陣列的維度是否為二維 (即 `(數量, 維度)` 格式)，以及是否為空。\n2.  **獲取嵌入維度**:\n    * 從 `all_chunk_embeddings_float32` 的形狀中獲取嵌入向量的維度 (dimension)。\n3.  **建立 FAISS 索引**:\n    * 使用 `faiss.IndexFlatL2(embedding_dimension)` 建立一個 FAISS 索引。`IndexFlatL2` 是一種基本的索引類型，它執行窮舉的 L2 距離（歐幾里得距離）搜索。對於中小型數據集，它既準確又高效。\n    * 檢查索引是否已「訓練」(is_trained)。`IndexFlatL2` 不需要額外的訓練步驟，所以 `is_trained` 會是 `True`。\n4.  **加入向量至索引**:\n    * 使用 `index.add(all_chunk_embeddings_float32)` 將所有文本區塊的嵌入向量加入到先前建立的 FAISS 索引中。\n    * 印出索引中向量的總數 (`index.ntotal`)，確認所有向量都已成功加入。","metadata":{}},{"cell_type":"code","source":"import faiss\nimport numpy as np\n\nprint(\"FAISS library imported.\")\n\nif 'all_chunk_embeddings' not in locals() or all_chunk_embeddings is None:\n    print(\"錯誤：找不到 'all_chunk_embeddings' 或其值為 None。請確保嵌入向量已在前一步驟中產生並在此會話中可用。\")\n    all_chunk_embeddings = np.random.rand(10, 768).astype(np.float32) # 範例：10 個嵌入向量，每個 768 維\n    print(\"正在使用虛擬 'all_chunk_embeddings' 數據進行測試。\")\nelse:\n    print(f\"找到 'all_chunk_embeddings'. 形狀 (Shape): {all_chunk_embeddings.shape}, 資料類型 (Dtype): {all_chunk_embeddings.dtype}\")\n\n    if all_chunk_embeddings.dtype != np.float32:\n        print(\"正在將嵌入向量轉換為 float32 型別...\")\n        all_chunk_embeddings_float32 = all_chunk_embeddings.astype(np.float32) # 轉換為 float32 型別的嵌入向量\n    else:\n        all_chunk_embeddings_float32 = all_chunk_embeddings # 若已是 float32 則直接使用\n\n    if all_chunk_embeddings_float32.ndim != 2:\n        print(f\"錯誤：'all_chunk_embeddings_float32' 不是一個二維陣列。它的形狀是 {all_chunk_embeddings_float32.shape}.\")\n        print(\"FAISS 需要二維的嵌入向量陣列 (數量, 維度)。\")\n        print(\"請檢查前一個嵌入步驟，確保輸出是正確的。\")\n    elif all_chunk_embeddings_float32.shape[0] == 0:\n        print(\"錯誤：'all_chunk_embeddings_float32' 是空的 (0 個嵌入向量)。無法建立 FAISS 索引。\")\n    else:\n        embedding_dimension = all_chunk_embeddings_float32.shape[1] # 嵌入向量的維度\n        print(f\"嵌入向量維度: {embedding_dimension}\")\n\n        print(\"正在建立 FAISS 索引 (IndexFlatL2)...\")\n        index = faiss.IndexFlatL2(embedding_dimension) # FAISS L2 平面索引\n        print(f\"FAISS 索引已建立。是否已訓練 (Is trained): {index.is_trained}\")\n\n        print(\"正在將嵌入向量加入 FAISS 索引...\")\n        index.add(all_chunk_embeddings_float32)\n        print(f\"嵌入向量已加入索引。索引中向量總數: {index.ntotal}\")\n\nprint(\"FAISS 索引過程完成 (或因錯誤而終止)。\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:13.964427Z","iopub.execute_input":"2025-05-26T02:59:13.964999Z","iopub.status.idle":"2025-05-26T02:59:14.015637Z","shell.execute_reply.started":"2025-05-26T02:59:13.964979Z","shell.execute_reply":"2025-05-26T02:59:14.014411Z"}},"outputs":[{"name":"stdout","text":"FAISS library imported.\n找到 'all_chunk_embeddings'. 形狀 (Shape): (43, 1024), 資料類型 (Dtype): float32\n嵌入向量維度: 1024\n正在建立 FAISS 索引 (IndexFlatL2)...\nFAISS 索引已建立。是否已訓練 (Is trained): True\n正在將嵌入向量加入 FAISS 索引...\n嵌入向量已加入索引。索引中向量總數: 43\nFAISS 索引過程完成 (或因錯誤而終止)。\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 查詢處理 (Query Processing)\n\n在建立好文本嵌入的向量索引後，下一步是處理使用者的查詢。與處理原始文本數據類似，使用者提出的查詢語句也需要被轉換成嵌入向量，才能在向量空間中與文本區塊的嵌入進行比較。\n\n此階段的流程：\n1.  **定義使用者查詢**:\n    * 設定一個字串變數 `user_query` 來儲存使用者輸入的查詢內容。例如：\"台積電2025年第一季的營收表現如何？\"\n2.  **嵌入使用者查詢**:\n    * 檢查先前載入的 `embedding_model_stella` 是否可用。\n    * 如果模型可用，則使用該模型的 `encode()` 方法將 `user_query` 轉換為一個查詢嵌入向量 (`query_embedding`)。這個過程與先前嵌入文本區塊的過程相同，確保查詢和文檔的向量處於同一個語義空間。\n3.  **調整嵌入向量形狀與型別**:\n    * FAISS 索引進行搜索時，期望輸入的查詢向量是一個二維陣列，即使只有一個查詢，也應該是 `(1, 維度)` 的形狀。因此，使用 `reshape(1, -1)` 來調整查詢嵌入向量的形狀。\n    * 同樣地，確保查詢嵌入向量的數據類型為 `numpy.float32`，如果不是則進行轉換。轉換後的向量儲存於 `query_embedding_final`。\n4.  **結果檢視**:\n    * 印出查詢嵌入成功轉換的訊息。\n    * 顯示最終查詢嵌入向量的形狀以及其前10個維度的值，作為驗證。\n    * 如果嵌入模型未載入，則會印出錯誤訊息。","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nuser_query = \"台積電2025年第一季的營收表現如何？\" # 使用者輸入的查詢語句\nprint(f\"User query: {user_query}\")\n\nif 'embedding_model_stella' in locals() and embedding_model_stella is not None:\n    print(\"Encoding user query using the loaded sentence-transformer model...\")\n    query_embedding = embedding_model_stella.encode(user_query) # 查詢語句的嵌入向量\n    \n    query_embedding_reshaped = query_embedding.reshape(1, -1) # 重塑為 FAISS 所需的 (1, 維度) 嵌入向量\n    \n    if query_embedding_reshaped.dtype != np.float32:\n        print(\"Converting query embedding to float32...\")\n        query_embedding_final = query_embedding_reshaped.astype(np.float32) # 轉換為 float32 型別的最終查詢嵌入\n    else:\n        query_embedding_final = query_embedding_reshaped # 若已是 float32 則直接使用\n        \n    print(\"Query encoded successfully.\")\n    print(f\"Query embedding shape: {query_embedding_final.shape}\")\n    print(\"Query embedding (first 10 dimensions):\")\n    print(query_embedding_final[0, :10])\nelse:\n    print(\"Error: 'embedding_model_stella' not found. Please ensure the embedding model is loaded.\")\n    # query_embedding_final = None # 或以適當方式處理錯誤 (此為錯誤處理的備註)\n\nprint(\"Query processing complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:14.016250Z","iopub.execute_input":"2025-05-26T02:59:14.016451Z","iopub.status.idle":"2025-05-26T02:59:14.434691Z","shell.execute_reply.started":"2025-05-26T02:59:14.016436Z","shell.execute_reply":"2025-05-26T02:59:14.434068Z"}},"outputs":[{"name":"stdout","text":"User query: 台積電2025年第一季的營收表現如何？\nEncoding user query using the loaded sentence-transformer model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df282702bdb64d62b9e1e682f58dab41"}},"metadata":{}},{"name":"stdout","text":"Query encoded successfully.\nQuery embedding shape: (1, 1024)\nQuery embedding (first 10 dimensions):\n[-1.0753199   1.001349   -1.4803534   0.32557517  0.49438864 -0.48533317\n  0.5334926  -0.66565585  1.1401933   0.07865802]\nQuery processing complete.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 相似度搜索 (Similarity Search)\n\n有了使用者查詢的嵌入向量以及包含所有文檔區塊嵌入的 FAISS 索引後，就可以執行相似度搜索了。目標是從索引中找出與使用者查詢最相關（即向量空間中距離最近）的 K 個文本區塊。\n\n此階段的步驟：\n1.  **設定搜索參數**:\n    * `k`: 指定要檢索的最近鄰居的數量（即最相似的文本區塊數量）。在此範例中設定為 5。\n2.  **執行搜索前檢查**:\n    * 檢查 FAISS 索引 (`index`) 是否已成功建立且可用。\n    * 檢查使用者查詢的最終嵌入向量 (`query_embedding_final`) 是否已準備好。\n    * 檢查 FAISS 索引中是否包含向量 (`index.ntotal == 0`)，如果索引為空，則無法進行搜索。\n3.  **執行 FAISS 搜索**:\n    * 如果所有檢查都通過，則調用 `index.search(query_embedding_final, k)` 方法。\n    * 此方法會返回兩個結果：\n        * `D`: 一個二維陣列，包含查詢向量與 `k` 個最近鄰居之間的距離（L2 距離）。\n        * `I`: 一個二維陣列，包含 `k` 个最近鄰居在原始 `all_chunks` 列表（即加入索引時的順序）中的索引值。\n4.  **展示搜索結果**:\n    * 印出搜索到的前 `k` 個結果的距離 (`D`) 和索引 (`I`)。\n    * 遍歷搜索結果，對於每個結果：\n        * 獲取其在 `all_chunks` 中的索引 (`chunk_index`) 和與查詢的相似度分數（距離 `distance`）。\n        * 如果索引有效，則從 `all_chunks` 中提取對應的文本區塊內容 (`retrieved_chunk`)。\n        * 同時，如果 `all_file_names` 可用，則顯示該區塊的來源檔案名稱。\n        * 將排名、索引、相似度分數、來源檔案和區塊內容格式化輸出。\n    * 如果 `all_chunks` 列表不可用或搜索結果為空，則印出相應提示。","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nk = 5 # 要檢索的最近鄰居數量\n\nif 'index' not in locals() or index is None:\n    print(\"Error: FAISS 'index' not found. Please ensure the index was created in a previous step.\")\nelif 'query_embedding_final' not in locals() or query_embedding_final is None:\n    print(\"Error: 'query_embedding_final' not found. Please ensure the user query was processed and embedded.\")\nelif index.ntotal == 0:\n    print(\"Error: The FAISS index is empty. No vectors to search.\")\nelse:\n    print(f\"Searching for the top {k} most similar chunks in the FAISS index...\")\n    D, I = index.search(query_embedding_final, k) # D 為距離列表, I 為索引列表\n    \n    print(\"\\nSearch complete.\")\n    print(f\"Distances of the top {k} results: {D}\")\n    print(f\"Indices of the top {k} results in 'all_chunks': {I}\")\n    \n    print(\"\\n--- Top Relevant Chunks ---\")\n    if 'all_chunks' in locals() and all_chunks is not None and 'I' in locals() and I is not None and len(I[0]) > 0 :\n        for i in range(k):\n            if i < len(I[0]):\n                chunk_index = I[0][i] # 檢索到的區塊在 all_chunks 中的索引\n                distance = D[0][i] # 檢索到的區塊與查詢的距離\n                if chunk_index < len(all_chunks):\n                    retrieved_chunk = all_chunks[chunk_index] # 根據索引獲取的實際文本區塊\n                    print(f\"\\nRank {i+1}:\")\n                    print(f\"Index in all_chunks: {chunk_index}\")\n                    print(f\"Similarity Score (Distance): {distance:.4f}\")\n                    if 'all_file_names' in locals() and all_file_names is not None and chunk_index < len(all_file_names):\n                        print(f\"Source File: {all_file_names[chunk_index]}\")\n                    print(\"Chunk Content:\")\n                    print(retrieved_chunk)\n                    print(\"--------------------\")\n                else:\n                    print(f\"\\nRank {i+1}: Index {chunk_index} is out of bounds for 'all_chunks'.\")\n            else:\n                print(f\"\\nCould not retrieve Rank {i+1} result (not enough search results).\")\n    else:\n        print(\"\\n'all_chunks' list not found or search results 'I' are missing/empty. Cannot display chunk content.\")\n\nprint(\"Similarity search process complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:14.435400Z","iopub.execute_input":"2025-05-26T02:59:14.435675Z","iopub.status.idle":"2025-05-26T02:59:15.916679Z","shell.execute_reply.started":"2025-05-26T02:59:14.435653Z","shell.execute_reply":"2025-05-26T02:59:15.915830Z"}},"outputs":[{"name":"stdout","text":"Searching for the top 5 most similar chunks in the FAISS index...\n\nSearch complete.\nDistances of the top 5 results: [[348.8439  381.25537 406.23102 439.98383 468.9683 ]]\nIndices of the top 5 results in 'all_chunks': [[12 11 13 31  1]]\n\n--- Top Relevant Chunks ---\n\nRank 1:\nIndex in all_chunks: 12\nSimilarity Score (Distance): 348.8439\nSource File: (TSMC).txt\nChunk Content:\n一、 最近期財報表現 (2025年第一季)\n\n台積電最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現強勁：\n\n營收：約為255.3億美元（年增約35.3%），以新台幣計價約為8,392.5億元。\n毛利率：達到58.8%。\n營業利益率：為48.5%。\n每股盈餘 (EPS)：約為新台幣13.94元（年增約60.4%）。\n從製程技術來看，3奈米製程佔晶圓總營收的22%，5奈米製程佔37%，7奈米製程佔15%。包含7奈米及更先進製程的營收佔晶圓總營收的73%。公司指出，第一季的業績雖然受到智慧型手機季節性因素的影響，但AI相關需求的持續成長部分抵銷了此影響。\n\n二、 市場分析與公司未來展望\n\n市場分析師普遍肯定AI相關的高效能運算（HPC）需求將持續作為台積電營運成長的核心動力，並對其技術領先地位（特別是3奈米、5奈米及即將量產的2奈米製程）給予正面評價。\n\n台積電管理層在2025年4月的法人說明會上，對未來營運釋出了以下展望：\n\n2025年第二季財務預測：\n營收預計介於284億美元至292億美元之間。\n毛利率預計介於57%至59%之間。\n營業利益率預計介於47%至49%之間。\n2025年全年展望：\n公司重申2025年美元營收將實現「近中雙位數」（約24-26%）的年成長。\nAI需求預期持續強勁，其他應用市場則預期溫和復甦。\n全年資本支出預算維持在380億至420億美元，以支持客戶成長與技術發展。\n分析師與公司均注意到地緣政治（如美中貿易關係、潛在關稅）及全球宏觀經濟的不確定性是主要的外部風險，但公司目前觀察客戶行為未因潛在關稅政策而改變。海外晶圓廠的擴建進度、成本控制及其對毛利率的短期影響（預期2025年可能稀釋毛利率約2-3個百分點）也是市場關注的焦點。\n\n三、 影響營運的主要正面與負面因素\n\n綜合來看，影響台積電近期財務表現及未來展望的因素如下：\n\n主要正面因素：\n\nAI需求強勁：AI晶片對先進製程及先進封裝的需求是核心成長引擎。\n技術領先：3奈米和5奈米製程的市場份額，以及2奈米製程的研發進度，鞏固了競爭優勢。\nHPC平台成長：除AI外，其他高效能運算應用亦帶動需求。\n汽車電子化趨勢：車用半導體含量提升帶來長期成長機會。\n部分終端市場溫和復甦：預期智慧型手機等市場將逐步回暖。\n主要負面因素與挑戰：\n--------------------\n\nRank 2:\nIndex in all_chunks: 11\nSimilarity Score (Distance): 381.2554\nSource File: (TSMC).txt\nChunk Content:\n台積電的客戶群體非常廣泛，主要包括全球頂尖的無晶圓廠IC設計公司 (Fabless)、系統公司以及部分IDM。雖然台積電通常不直接公開其客戶的具體名單和各別貢獻的詳細數據，但根據公開資訊和法人推估，其主要客戶包括：\n\n蘋果 (Apple Inc.)：為其iPhone、iPad、Mac等產品線提供處理器晶片，是台積電最大的客戶。\n輝達 (NVIDIA)：AI晶片和GPU的主要供應商。\n超微 (AMD)：CPU和GPU的主要供應商。\n高通 (Qualcomm)：手機處理器和通訊晶片的主要供應商。\n聯發科 (MediaTek)：手機處理器和其他消費性電子晶片的主要供應商。\n英特爾 (Intel)：部分產品委外代工。\n博通 (Broadcom)：網通晶片等。\n這些客戶主要屬於高效能運算、智慧型手機、汽車電子、物聯網及消費性電子等產業。\n\n主要營收來源：\n\n台積電的營收主要來自於晶圓代工服務，其營收佔比會因技術節點和應用平台的市場需求而有所不同。根據近期（截至2024年底及2025年初）的公開資訊，主要營收貢獻來自：\n\n依技術平台區分：\n\n高效能運算 (HPC)：在2024年第四季度及全年佔營收比重最高，超過50%。\n智慧型手機：佔營收比重約35%。\n物聯網 (IoT)：約佔5-6%。\n汽車電子 (Automotive)：約佔4-5%。\n消費性電子 (DCE)：佔比較低，約1-2%。\n（請注意：以上比例為概略值，實際數字會隨每季財報更新。）\n依製程技術節點區分：\n\n先進製程（如3奈米、5奈米、7奈米）是營收的主要貢獻來源。例如，2024年3奈米製程已佔晶圓營收的18%，5奈米佔34%，7奈米佔17%。整體而言，7奈米及以下的先進製程佔晶圓總營收的近七成。\n台積電憑藉其在先進製程技術的持續領先和穩定的產能供應，在全球半導體產業中持續保持其核心競爭力。\n\n\n一、 最近期財報表現 (2025年第一季)\n\n台積電最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現強勁：\n--------------------\n\nRank 3:\nIndex in all_chunks: 13\nSimilarity Score (Distance): 406.2310\nSource File: (TSMC).txt\nChunk Content:\n主要正面因素：\n\nAI需求強勁：AI晶片對先進製程及先進封裝的需求是核心成長引擎。\n技術領先：3奈米和5奈米製程的市場份額，以及2奈米製程的研發進度，鞏固了競爭優勢。\nHPC平台成長：除AI外，其他高效能運算應用亦帶動需求。\n汽車電子化趨勢：車用半導體含量提升帶來長期成長機會。\n部分終端市場溫和復甦：預期智慧型手機等市場將逐步回暖。\n主要負面因素與挑戰：\n\n地緣政治風險與貿易摩擦：全球供應鏈穩定性及市場信心受外部政治因素影響。\n全球宏觀經濟不確定性：通膨、利率及經濟成長趨緩可能抑制終端需求。\n特定市場波動：如智慧型手機市場的季節性因素。\n海外設廠的成本與效率：新廠初期可能面臨較高成本及對毛利率的短期壓力。\n營運成本上升：電價、原物料及人力成本對利潤率構成挑戰。\n整體而言，在AI需求的強力驅動下，市場對台積電2025年的營運表現抱持相對樂觀的預期，但同時也密切關注外部環境的變化及其潛在影響。\n--------------------\n\nRank 4:\nIndex in all_chunks: 31\nSimilarity Score (Distance): 439.9838\nSource File: (UMC).txt\nChunk Content:\n主要營收來源：\n\n聯電的營收主要來自於晶圓代工服務。其營收佔比會因製程節點和終端應用市場的需求而有所不同。根據近期（截至2024年底及2025年初）的公開資訊和法人分析，其營收來源大致如下：\n\n依終端應用市場（2024年第四季數據，可供參考）：\n\n通訊：約佔營收的40-45%。\n消費性電子：約佔營收的20-25%。\n電腦：約佔營收的15-20%。\n汽車：約佔營收的10-15%，為成長較快的領域。\n其他（含工業等）：約佔營收的5-10%。\n（請注意：以上比例為概略值，實際數字會隨每季財報更新。）\n依製程技術節點：\n\n聯電的營收主要來自於成熟製程，例如22/28奈米、40奈米、65奈米以及更成熟的製程節點。其中，22/28奈米製程是其重要的營收貢獻來源之一。相較於追求最先進製程的競爭對手，聯電在特殊製程如高壓製程、嵌入式非揮發性記憶體製程等方面也佔有重要地位。\n聯電透過其穩健的製造能力、多元化的製程技術組合以及具成本效益的解決方案，持續在全球半導體晶圓代工市場扮演重要角色。\n\n一、 最近期財報表現 (2025年第一季)\n\n聯華電子最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據如下：\n\n營收：新台幣 585 億元（年增約 5%，季增約 3%）。\n毛利率：33.5%（略優於公司先前預期）。\n營業利益率：22.8%。\n每股盈餘 (EPS)：約為新台幣 1.25 元。\n產能利用率：約 75%。\n公司表示，2025年第一季的營運表現主要受惠於電腦、消費及通訊領域的庫存回補需求，以及車用和工業領域需求的穩定貢獻。28奈米製程的營收佔比持續提升。\n\n二、 市場分析與公司未來展望\n\n市場分析師對於聯電的看法，多聚焦於成熟製程的市場供需動態、公司在特殊製程的佈局，以及車用和工業等非消費性市場的成長潛力。\n\n聯華電子管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：\n--------------------\n\nRank 5:\nIndex in all_chunks: 1\nSimilarity Score (Distance): 468.9683\nSource File: (MediaTek) .txt\nChunk Content:\n聯發科的客戶群體主要是全球各大終端產品品牌商和原始設計製造商 (ODM)。雖然聯發科通常不公開其具體客戶名單，但其客戶主要屬於以下產業或類型：\n\n智慧型手機品牌商：涵蓋全球多個主要的手機製造商。\n消費性電子產品製造商：生產智慧電視、平板電腦、路由器、智慧音箱、穿戴裝置等的廠商。\n物聯網設備開發商：涵蓋工業、零售、醫療等多元領域。\n汽車零組件供應商及汽車製造商：在智慧汽車領域的合作夥伴。\n雲端服務供應商及企業客戶：在客製化AI晶片領域的潛在及現有客戶。\n主要營收來源：\n\n聯發科的營收主要來自其各類晶片產品的銷售。根據近期（截至2024年底及2025年第一季）的公開資訊，其主要營收來源大致如下：\n\n行動通訊 (Mobile Phone)：主要為智慧型手機處理器等。在2025年第一季，此部分約佔總營收的 56%。\n智慧終端平台 (Smart Edge Platforms)：此類別涵蓋智慧家庭（如電視、路由器）、平板電腦、Chromebook、物聯網、ASIC（客製化晶片）、車用電子等。在2025年第一季，此部分約佔總營收的 38%。\n電源管理IC (Power IC)：約佔總營收的 6% (2025年第一季數據)。\n具體各產品線的營收佔比會因市場需求、新產品週期及季節性因素而有所波動。近年來，除了穩固其在智慧型手機市場的地位外，聯發科也積極拓展在智慧物聯網、汽車電子以及AI相關領域的市場，以實現營收來源的多元化。\n\n一、 最近期財報表現 (2025年第一季)\n\n聯發科最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現穩健：\n\n營收：新台幣 1355 億元（年增約 32%，季減約 8%）。\n毛利率：48.5%（符合公司預期，年增0.5個百分點）。\n營業利益率：18.2%。\n每股盈餘 (EPS)：約為新台幣 19.85 元。\n公司指出，2025年第一季營收表現主要受惠於手機客戶庫存回補以及旗艦手機晶片（如天璣9400系列）出貨暢旺。智慧裝置平台（Smart Edge Platform）業務也維持成長動能。\n\n二、 市場分析與公司未來展望\n--------------------\nSimilarity search process complete.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\ntry:\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\") # \"HF_TOKEN\" 是您在 Secrets 中設定的名稱\n    login(token=hf_token)\n    print(\"Hugging Face Hub login successful using Kaggle Secrets.\")\nexcept Exception as e:\n    print(f\"Hugging Face Hub login failed using Kaggle Secrets: {e}\")\n    print(\"Please ensure you have added your Hugging Face token as a secret named 'HF_TOKEN' in your Kaggle Notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:15.917610Z","iopub.execute_input":"2025-05-26T02:59:15.917913Z","iopub.status.idle":"2025-05-26T02:59:17.344864Z","shell.execute_reply.started":"2025-05-26T02:59:15.917890Z","shell.execute_reply":"2025-05-26T02:59:17.343966Z"}},"outputs":[{"name":"stdout","text":"Hugging Face Hub login successful using Kaggle Secrets.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# !pip install transformers accelerate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:17.345905Z","iopub.execute_input":"2025-05-26T02:59:17.346254Z","iopub.status.idle":"2025-05-26T02:59:18.336737Z","shell.execute_reply.started":"2025-05-26T02:59:17.346223Z","shell.execute_reply":"2025-05-26T02:59:18.335809Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import pipeline\nfrom langchain_community.llms import HuggingFacePipeline\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\nprint(\"Libraries imported successfully.\")\n\nmodel_id_original = \"taide/Llama3-TAIDE-LX-8B-Chat-Alpha1\" # 原始模型的 Hugging Face ID\nmodel_id_for_loading = model_id_original # 預設使用原始模型ID，如果找不到GPTQ版本\n\nprint(f\"Attempting to load model: {model_id_for_loading}\")\nprint(\"Note: If this is not a specifically GPTQ-quantized model ID,\")\nprint(\"this loading method might not apply quantization as intended without 'bitsandbytes'.\")\n\nprint(f\"Loading tokenizer for {model_id_original}...\")\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(model_id_original) # 載入的 Hugging Face Tokenizer 物件\n    print(\"Tokenizer loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading tokenizer: {e}\")\n    tokenizer = None # Tokenizer 載入失敗，設為 None\n\nif tokenizer is not None:\n    print(f\"Loading model {model_id_for_loading} (this may take some time and RAM)...\")\n    try:\n        llm_model = AutoModelForCausalLM.from_pretrained( # 載入的 Hugging Face LLM 模型物件\n            model_id_for_loading,\n            device_map=\"auto\", # 自動分配模型到可用設備 (CPU/GPU)\n            torch_dtype=torch.float16 # GPTQ 通常使用 float16 或 bfloat16\n        )\n        print(\"LLM model loaded successfully.\")\n        print(f\"Model device map: {llm_model.hf_device_map if hasattr(llm_model, 'hf_device_map') else 'N/A'}\")\n\n    except Exception as e:\n        print(f\"Error loading LLM model: {e}\")\n        print(\"Possible reasons include: model ID not found, insufficient RAM/GPU memory,\")\n        print(\"or the model is not in a compatible format for direct loading without specific quantization libraries.\")\n        print(f\"If '{model_id_for_loading}' is a GPTQ model, ensure 'optimum' and 'auto-gptq' are installed and you've restarted the runtime.\")\n        llm_model = None # 模型載入失敗，設為 None\nelse:\n    print(\"Skipping model loading due to tokenizer loading failure.\")\n    llm_model = None # Tokenizer 載入失敗導致模型無法載入，設為 None\n\nprint(\"\\nLLM and Tokenizer loading process complete (or terminated due to errors).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T02:59:18.337700Z","iopub.execute_input":"2025-05-26T02:59:18.338008Z","iopub.status.idle":"2025-05-26T03:01:01.225851Z","shell.execute_reply.started":"2025-05-26T02:59:18.337984Z","shell.execute_reply":"2025-05-26T03:01:01.225233Z"}},"outputs":[{"name":"stdout","text":"Libraries imported successfully.\nAttempting to load model: taide/Llama3-TAIDE-LX-8B-Chat-Alpha1\nNote: If this is not a specifically GPTQ-quantized model ID,\nthis loading method might not apply quantization as intended without 'bitsandbytes'.\nLoading tokenizer for taide/Llama3-TAIDE-LX-8B-Chat-Alpha1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a3a2237e624993ad8ea0ae05334ca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3019cebc8fbd480dbbd295dac56d303f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ffb464db4b4b60aae89c1e75451c25"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded successfully.\nLoading model taide/Llama3-TAIDE-LX-8B-Chat-Alpha1 (this may take some time and RAM)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b0b8b1452648e6be5c6291b9b523a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a65224dec34dbb88601ad97cd83b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2644b3050b1043568710621c30927f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb18addc64ca472d901b01a4f980cbaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50a1ba09ee304315a41a75d20f0735ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f64fd0d8ea22491f8dd1b8f3ce10a052"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f67f6a280ccb4d62a0ee1491a8ab2848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96679c59d5e4035a5ed25631121af88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/143 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc6b0035d8684490ae581d4bfca06d9e"}},"metadata":{}},{"name":"stdout","text":"LLM model loaded successfully.\nModel device map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}\n\nLLM and Tokenizer loading process complete (or terminated due to errors).\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### LLM查詢與上下文整合 (LLM Query with Context Integration)\n大型語言模型 (LLM) 根據提供的上下文來回答使用者的問題。\n主要流程：\n1.  **接收輸入**：包括使用者問題、檢索到的上下文、已載入的LLM模型及Tokenizer。\n2.  **建立管線**：設定一個 `transformers` 的文本生成管線，使用指定的模型和Tokenizer。\n3.  **提示工程**：透過 `PromptTemplate` 指導LLM依據上下文回答，若無答案則明說，並要求以繁體中文作答。\n4.  **執行與獲取答案**：建立並執行 `LLMChain`，傳入問題與上下文，最後提取並返回LLM生成的答案。","metadata":{}},{"cell_type":"code","source":"def query_llm_with_context(user_question: str, retrieved_context_str: str, llm_model_loaded, tokenizer_loaded):\n    print(f\"LLM 將回答的問題: {user_question}\")\n\n    if llm_model_loaded is None or tokenizer_loaded is None:\n        print(\"錯誤: LLM 模型或 Tokenizer 未載入。\")\n        return \"錯誤：模型或 Tokenizer 未載入。\"\n    if not retrieved_context_str or retrieved_context_str.isspace():\n        print(\"警告: 提供的上下文為空。模型將主要依賴其內部知識。\")\n\n    try:\n        text_generation_pipeline = pipeline(\n            task=\"text-generation\",\n            model=llm_model_loaded,\n            tokenizer=tokenizer_loaded,\n            torch_dtype=llm_model_loaded.dtype,\n            device_map=\"auto\",\n            max_new_tokens=512,\n        )\n        llm_hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n\n        prompt_template_with_context_str = \"\"\"請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n{context}\n\n問題：{question}\n\n答案（請使用繁體中文回答）：\"\"\"\n        \n        prompt_with_context = PromptTemplate(\n            template=prompt_template_with_context_str,\n            input_variables=[\"context\", \"question\"]\n        )\n        llm_chain_with_context = LLMChain(llm=llm_hf, prompt=prompt_with_context)\n        \n        chain_input = {\"question\": user_question, \"context\": retrieved_context_str}\n        chain_output = llm_chain_with_context.invoke(chain_input)\n        final_answer = chain_output.get(\"text\", \"無法從鏈的輸出中找到答案。\")\n        \n        print(\"\\n--- 模型基於上下文生成的答案 ---\")\n        print(final_answer)\n        print(\"-----------------------------------\")\n        return final_answer\n\n    except Exception as e:\n        print(f\"在設定或執行 LLM 管線時發生錯誤: {e}\")\n        return f\"執行時發生錯誤: {e}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:01:01.226716Z","iopub.execute_input":"2025-05-26T03:01:01.227004Z","iopub.status.idle":"2025-05-26T03:01:01.234058Z","shell.execute_reply.started":"2025-05-26T03:01:01.226968Z","shell.execute_reply":"2025-05-26T03:01:01.233493Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### 完整 RAG 查詢流程 (Rigorous RAG Query Process)\n執行一個完整的「檢索增強生成」(RAG)流程，結合資訊檢索與語言模型生成答案。\n主要流程：\n1.  **接收輸入**：包括使用者問題、嵌入模型、FAISS索引、所有文本區塊、LLM模型及Tokenizer。\n2.  **上下文檢索 (Retrieval)**：\n    * **問題嵌入**：將使用者問題轉換為嵌入向量。\n    * **相似性搜索**：使用FAISS索引找出與問題嵌入最相關的文本區塊。\n    * **上下文整合**：將檢索到的相關文本區塊合併成單一的上下文資訊字串。\n3.  **答案生成 (Generation)**：\n    * 呼叫 `query_llm_with_context` 函式，將原始問題和整合後的上下文傳遞給LLM以生成答案。\n4.  **返回結果**：回傳LLM生成的最終答案以及檢索過程中使用的上下文區塊列表。","metadata":{}},{"cell_type":"code","source":"def perform_rigorous_rag_query(question_for_llm: str, \n                               embedding_model, \n                               faiss_index, \n                               all_document_chunks, \n                               llm_true_model, \n                               llm_tokenizer, \n                               k_results=3):\n\n    print(f\"\\n========== 開始 RAG 查詢 ==========\")\n    print(f\"步驟 1: 定義要問 LLM 的問題: \\\"{question_for_llm}\\\"\")\n\n    print(f\"\\n步驟 2: 為 \\\"{question_for_llm}\\\" 檢索上下文...\")\n    if embedding_model is None:\n        print(\"錯誤: 嵌入模型未提供。\")\n        return \"錯誤: 嵌入模型未提供。\"\n    if faiss_index is None:\n        print(\"錯誤: FAISS 索引未提供。\")\n        return \"錯誤: FAISS 索引未提供。\"\n    if not all_document_chunks:\n        print(\"錯誤: 文檔區塊列表為空。\")\n        return \"錯誤: 文檔區塊列表為空。\"\n\n    try:\n\n        print(\"  正在嵌入問題...\")\n        query_embedding = embedding_model.encode(question_for_llm)\n        query_embedding_reshaped = query_embedding.reshape(1, -1)\n        if query_embedding_reshaped.dtype != np.float32:\n            query_embedding_final = query_embedding_reshaped.astype(np.float32)\n        else:\n            query_embedding_final = query_embedding_reshaped\n        print(f\"  問題嵌入完成。形狀: {query_embedding_final.shape}\")\n\n\n        print(f\"  正在 FAISS 索引中搜索相似區塊 (k={k_results})...\")\n        if faiss_index.ntotal == 0:\n            print(\"錯誤: FAISS 索引是空的，無法搜索。\")\n            return \"錯誤: FAISS 索引是空的。\"\n        \n        distances, indices = faiss_index.search(query_embedding_final, k_results)\n        print(f\"  搜索完成。找到索引: {indices}\")\n\n\n        if len(indices[0]) == 0 or indices[0][0] == -1:\n             print(\"  未能檢索到任何相關上下文。\")\n             relevant_context_str = \"在此資料庫中找不到與問題相關的特定上下文。\"\n        else:\n            context_chunks_for_question = [\n                all_document_chunks[idx] for idx in indices[0] if idx < len(all_document_chunks) and idx != -1\n            ]\n            if not context_chunks_for_question:\n                print(\"  未能檢索到任何有效的上下文區塊。\")\n                relevant_context_str = \"在此資料庫中找不到與問題相關的特定上下文。\"\n            else:\n                print(f\"  成功提取 {len(context_chunks_for_question)} 個上下文區塊。\")\n                # relevant_context_str = \"\\n\\n---\\n\\n\".join(context_chunks_for_question) # 原來的合併方式\n                relevant_context_str = \" \".join(chunk.replace(\"\\n\", \" \") for chunk in context_chunks_for_question)\n\n\n    except Exception as e:\n        print(f\"  檢索上下文時發生錯誤: {e}\")\n        relevant_context_str = f\"檢索上下文時出錯 ({e})。\"\n\n    print(f\"\\n步驟 3: 使用檢索到的上下文查詢 LLM...\")\n    final_llm_answer = query_llm_with_context(\n        user_question=question_for_llm,\n        retrieved_context_str=relevant_context_str,\n        llm_model_loaded=llm_true_model,\n        tokenizer_loaded=llm_tokenizer\n    )\n    \n    # 新的返回，增加 context_chunks_for_question\n    print(f\"========== RAG 查詢結束 ==========\")\n    if 'context_chunks_for_question' not in locals():\n        # 處理未能檢索到任何上下文區塊的情況\n        context_chunks_for_question = []\n    return final_llm_answer, context_chunks_for_question\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:01:01.234753Z","iopub.execute_input":"2025-05-26T03:01:01.235014Z","iopub.status.idle":"2025-05-26T03:01:01.250717Z","shell.execute_reply.started":"2025-05-26T03:01:01.234992Z","shell.execute_reply":"2025-05-26T03:01:01.250011Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from datasets import Dataset\n\nquestions_for_eval = []\nanswers_for_eval = []\ncontexts_for_eval = []\n\n\nlist_of_questions_to_evaluate = [\n    \"台積電2026年第一季的營收表現如何？\",\n    \"公司遠傳的同期的財報表現差異為何？\",\n    \"聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\",\n]\n\n# list_of_questions_to_evaluate = [\n#     \"台積電2025年第一季的營收表現如何？\",\n#     \"TSMC、創意電子(GUC)、UMC的同期的財報表現差異為何？\",\n#     \"聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\",\n# ]\n\nif not ('embedding_model_stella' in locals() and\n        'index' in locals() and\n        'all_chunks' in locals() and\n        'llm_model' in locals() and\n        'tokenizer' in locals() and\n        callable(perform_rigorous_rag_query)):\n    print(\"錯誤：一個或多個必要的變數或函數未在 Notebook 中定義或初始化。\")\n    print(\"請確保您已成功執行 Notebook 的前面部分。\")\n    dataset = None\nelse:\n    print(f\"準備開始為 {len(list_of_questions_to_evaluate)} 個問題收集評估數據...\\n\")\n\n    for i, current_question in enumerate(list_of_questions_to_evaluate):\n        print(f\"正在處理問題 {i+1}/{len(list_of_questions_to_evaluate)}: '{current_question}'\")\n\n\n        generated_answer, retrieved_contexts_list = perform_rigorous_rag_query(\n            question_for_llm=current_question,\n            embedding_model=embedding_model_stella,\n            faiss_index=index,\n            all_document_chunks=all_chunks,\n            llm_true_model=llm_model,\n            llm_tokenizer=tokenizer,\n            k_results=3 \n        )\n        \n        print(f\"  問題 '{current_question}' 的 RAG 查詢完成。\")\n        if i > 0:\n            print(f\"    生成答案: {generated_answer}\")\n            print(f\"    檢索到的上下文數量: {len(retrieved_contexts_list)}\")\n            continue\n            \n        questions_for_eval.append(current_question)\n        answers_for_eval.append(generated_answer)\n        contexts_for_eval.append(retrieved_contexts_list)\n        print(\"-\" * 30)\n\n    print(\"\\n所有問題的數據收集完畢！\")\n\n    data_for_ragas = {\n        'question': questions_for_eval,\n        'answer': answers_for_eval,\n        'contexts': contexts_for_eval\n    }\n\n    if 'Dataset' in globals():\n        dataset = Dataset.from_dict(data_for_ragas)\n        print(\"\\n已使用 Notebook 中的變數成功創建包含多個問答對的 RAGAS 評估數據集:\")\n        print(dataset)\n    else:\n        print(\"\\n錯誤: `datasets.Dataset` 未導入。請確保已執行 `from datasets import Dataset`。\")\n        dataset = None ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:01:01.251480Z","iopub.execute_input":"2025-05-26T03:01:01.251684Z","iopub.status.idle":"2025-05-26T03:03:09.290839Z","shell.execute_reply.started":"2025-05-26T03:01:01.251670Z","shell.execute_reply":"2025-05-26T03:03:09.290137Z"}},"outputs":[{"name":"stdout","text":"準備開始為 3 個問題收集評估數據...\n\n正在處理問題 1/3: '台積電2026年第一季的營收表現如何？'\n\n========== 開始 RAG 查詢 ==========\n步驟 1: 定義要問 LLM 的問題: \"台積電2026年第一季的營收表現如何？\"\n\n步驟 2: 為 \"台積電2026年第一季的營收表現如何？\" 檢索上下文...\n  正在嵌入問題...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbf3294538aa481ca78dd3dc0d76352d"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"  問題嵌入完成。形狀: (1, 1024)\n  正在 FAISS 索引中搜索相似區塊 (k=3)...\n  搜索完成。找到索引: [[12 11 13]]\n  成功提取 3 個上下文區塊。\n\n步驟 3: 使用檢索到的上下文查詢 LLM...\nLLM 將回答的問題: 台積電2026年第一季的營收表現如何？\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/655924192.py:19: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm_hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n/tmp/ipykernel_35/655924192.py:34: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain_with_context = LLMChain(llm=llm_hf, prompt=prompt_with_context)\n","output_type":"stream"},{"name":"stdout","text":"\n--- 模型基於上下文生成的答案 ---\n請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n一、 最近期財報表現 (2025年第一季)  台積電最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現強勁：  營收：約為255.3億美元（年增約35.3%），以新台幣計價約為8,392.5億元。 毛利率：達到58.8%。 營業利益率：為48.5%。 每股盈餘 (EPS)：約為新台幣13.94元（年增約60.4%）。 從製程技術來看，3奈米製程佔晶圓總營收的22%，5奈米製程佔37%，7奈米製程佔15%。包含7奈米及更先進製程的營收佔晶圓總營收的73%。公司指出，第一季的業績雖然受到智慧型手機季節性因素的影響，但AI相關需求的持續成長部分抵銷了此影響。  二、 市場分析與公司未來展望  市場分析師普遍肯定AI相關的高效能運算（HPC）需求將持續作為台積電營運成長的核心動力，並對其技術領先地位（特別是3奈米、5奈米及即將量產的2奈米製程）給予正面評價。  台積電管理層在2025年4月的法人說明會上，對未來營運釋出了以下展望：  2025年第二季財務預測： 營收預計介於284億美元至292億美元之間。 毛利率預計介於57%至59%之間。 營業利益率預計介於47%至49%之間。 2025年全年展望： 公司重申2025年美元營收將實現「近中雙位數」（約24-26%）的年成長。 AI需求預期持續強勁，其他應用市場則預期溫和復甦。 全年資本支出預算維持在380億至420億美元，以支持客戶成長與技術發展。 分析師與公司均注意到地緣政治（如美中貿易關係、潛在關稅）及全球宏觀經濟的不確定性是主要的外部風險，但公司目前觀察客戶行為未因潛在關稅政策而改變。海外晶圓廠的擴建進度、成本控制及其對毛利率的短期影響（預期2025年可能稀釋毛利率約2-3個百分點）也是市場關注的焦點。  三、 影響營運的主要正面與負面因素  綜合來看，影響台積電近期財務表現及未來展望的因素如下：  主要正面因素：  AI需求強勁：AI晶片對先進製程及先進封裝的需求是核心成長引擎。 技術領先：3奈米和5奈米製程的市場份額，以及2奈米製程的研發進度，鞏固了競爭優勢。 HPC平台成長：除AI外，其他高效能運算應用亦帶動需求。 汽車電子化趨勢：車用半導體含量提升帶來長期成長機會。 部分終端市場溫和復甦：預期智慧型手機等市場將逐步回暖。 主要負面因素與挑戰： 台積電的客戶群體非常廣泛，主要包括全球頂尖的無晶圓廠IC設計公司 (Fabless)、系統公司以及部分IDM。雖然台積電通常不直接公開其客戶的具體名單和各別貢獻的詳細數據，但根據公開資訊和法人推估，其主要客戶包括：  蘋果 (Apple Inc.)：為其iPhone、iPad、Mac等產品線提供處理器晶片，是台積電最大的客戶。 輝達 (NVIDIA)：AI晶片和GPU的主要供應商。 超微 (AMD)：CPU和GPU的主要供應商。 高通 (Qualcomm)：手機處理器和通訊晶片的主要供應商。 聯發科 (MediaTek)：手機處理器和其他消費性電子晶片的主要供應商。 英特爾 (Intel)：部分產品委外代工。 博通 (Broadcom)：網通晶片等。 這些客戶主要屬於高效能運算、智慧型手機、汽車電子、物聯網及消費性電子等產業。  主要營收來源：  台積電的營收主要來自於晶圓代工服務，其營收佔比會因技術節點和應用平台的市場需求而有所不同。根據近期（截至2024年底及2025年初）的公開資訊，主要營收貢獻來自：  依技術平台區分：  高效能運算 (HPC)：在2024年第四季度及全年佔營收比重最高，超過50%。 智慧型手機：佔營收比重約35%。 物聯網 (IoT)：約佔5-6%。 汽車電子 (Automotive)：約佔4-5%。 消費性電子 (DCE)：佔比較低，約1-2%。 （請注意：以上比例為概略值，實際數字會隨每季財報更新。） 依製程技術節點區分：  先進製程（如3奈米、5奈米、7奈米）是營收的主要貢獻來源。例如，2024年3奈米製程已佔晶圓營收的18%，5奈米佔34%，7奈米佔17%。整體而言，7奈米及以下的先進製程佔晶圓總營收的近七成。 台積電憑藉其在先進製程技術的持續領先和穩定的產能供應，在全球半導體產業中持續保持其核心競爭力。   一、 最近期財報表現 (2025年第一季)  台積電最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現強勁： 主要正面因素：  AI需求強勁：AI晶片對先進製程及先進封裝的需求是核心成長引擎。 技術領先：3奈米和5奈米製程的市場份額，以及2奈米製程的研發進度，鞏固了競爭優勢。 HPC平台成長：除AI外，其他高效能運算應用亦帶動需求。 汽車電子化趨勢：車用半導體含量提升帶來長期成長機會。 部分終端市場溫和復甦：預期智慧型手機等市場將逐步回暖。 主要負面因素與挑戰：  地緣政治風險與貿易摩擦：全球供應鏈穩定性及市場信心受外部政治因素影響。 全球宏觀經濟不確定性：通膨、利率及經濟成長趨緩可能抑制終端需求。 特定市場波動：如智慧型手機市場的季節性因素。 海外設廠的成本與效率：新廠初期可能面臨較高成本及對毛利率的短期壓力。 營運成本上升：電價、原物料及人力成本對利潤率構成挑戰。 整體而言，在AI需求的強力驅動下，市場對台積電2025年的營運表現抱持相對樂觀的預期，但同時也密切關注外部環境的變化及其潛在影響。\n\n問題：台積電2026年第一季的營收表現如何？\n\n答案（請使用繁體中文回答）：根據台積電2025年第四季度（截至2024年12月31日）財報發布後的電話會議中，管理層針對2026年第一季的財務預測做出了以下說明：\n\n1. 營收預測：預計2026年第一季的營收將介於320億美元至330億美元之間，較2025年同期成長約20%至22%，但低於2025年第四季度的季增率。\n2. 毛利率預測：預計2026年第一季的毛利率將介於55%至57%之間，略低於2025年第一季的58.8%，主因是生產成本的上升以及匯率因素。\n3. 營業利益率預測：預計2026年第一季的營業利益率將介於45%至47%之間，略低於2025年第一季的48.5%。\n4. 每股盈餘（EPS）預測：預計2026年第一季的EPS將約為新台幣10.5元至10.7元之間，低於2025年第一季的新台幣13.94元。\n\n需要注意的是，半導體產業屬於景氣循環型產業，市場需求會受到季節性因素和總體經濟環境的影響。雖然台積電在先進製程技術上保持領先地位，但仍然面臨著地緣政治、通貨膨脹、利率上升等不確定性因素的挑戰。然而，隨著AI、5G、物聯網、高效能運算等技術的持續發展，台積電的長期成長潛力仍被業界看好。然而，實際的營收表現仍可能受到多方面因素的影響，建議持續關注台積電的官方公告和產業動態。\n\n\n根據台積電2025年第四季度（截至2024年12月31日）財報發布後的電話會議中，管理層針對2026年第一季的財務預測做出了以下說明：\n\n1. 營收預\n-----------------------------------\n========== RAG 查詢結束 ==========\n  問題 '台積電2026年第一季的營收表現如何？' 的 RAG 查詢完成。\n------------------------------\n正在處理問題 2/3: '公司遠傳的同期的財報表現差異為何？'\n\n========== 開始 RAG 查詢 ==========\n步驟 1: 定義要問 LLM 的問題: \"公司遠傳的同期的財報表現差異為何？\"\n\n步驟 2: 為 \"公司遠傳的同期的財報表現差異為何？\" 檢索上下文...\n  正在嵌入問題...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ee5ca195c4443f7902fec57d244dec8"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"  問題嵌入完成。形狀: (1, 1024)\n  正在 FAISS 索引中搜索相似區塊 (k=3)...\n  搜索完成。找到索引: [[18 37 28]]\n  成功提取 3 個上下文區塊。\n\n步驟 3: 使用檢索到的上下文查詢 LLM...\nLLM 將回答的問題: 公司遠傳的同期的財報表現差異為何？\n\n--- 模型基於上下文生成的答案 ---\n請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n三、 影響營運的主要正面與負面因素  綜合來看，影響祥碩近期財務表現及未來展望的因素如下：  主要正面因素：  與主要客戶（AMD）的緊密合作：AMD在CPU市場市佔率的提升，直接帶動祥碩晶片組及高速介面控制晶片的需求。 技術領先優勢：在USB4、PCIe Gen5/Gen6等高速傳輸介面技術上保持領先，受惠於新技術標準的升級週期。 AI與HPC需求帶動：數據中心、AI伺服器等高效能運算應用對高速傳輸介面需求強勁。 新產品與新市場：USB4 v2產品的開發、車用市場的佈局以及Techpoint的併購，為未來成長增添動能。 穩健的財務結構：持續維持高毛利率（約50%以上）、低負債比及充裕的現金部位。 特定市場競爭格局有利：如在中國市場特定產品線的競爭相對有限。 主要負面因素與挑戰：  半導體產業的週期性波動：整體產業景氣循環仍可能對公司營運帶來影響。 技術快速迭代的研發壓力：為維持技術領先，需持續投入高額研發費用。 全球供應鏈風險：需有效管理晶圓產能取得及供應商關係。 市場競爭：雖然在特定領域具領先優勢，但整體IC設計產業競爭依然存在，需專注技術差異化以避免價格戰。 對主要客戶的依賴性：主要客戶的市場表現與採購策略對祥碩營運有顯著影響。 毛利率波動：雖維持高檔，但仍可能受產品組合、市場競爭等因素影響而波動。 整體而言，祥碩憑藉其在高速傳輸技術的領導地位及與關鍵客戶的深度合作，在AI與HPC趨勢的帶動下，2025年營運前景看好。市場將持續關注其新產品的市場滲透速度、主要客戶的拉貨動能以及整體產業的復甦情況。 三、 影響營運的主要正面與負面因素  綜合來看，影響聯詠近期財務表現及未來展望的因素如下：  主要正面因素：  OLED滲透率提升：OLED面板在智慧型手機、穿戴裝置、平板、筆電及高階電視的應用持續擴大，帶動OLED DDI需求強勁成長。 TV市場回溫與規格升級：大型體育賽事（如奧運）可能刺激TV換機潮，且TV SoC規格持續升級（如8K、高刷新率、AI影像處理）。 車用電子成長潛力：汽車智慧化及電子化趨勢，帶動車用顯示器驅動IC、時序控制晶片(TCON)、影像感測器(CIS)等產品需求。 ASIC與AI相關機會：投入客製化晶片（ASIC）開發，以及佈局邊緣運算AI相關的影像處理SoC。 供應鏈庫存健康化：若終端市場庫存水位恢復健康，有利於訂單能見度及拉貨動能。 主要負面因素與挑戰：  成熟產品價格競爭：LCD DDI等成熟市場面臨來自中國大陸及其他競爭對手的價格壓力。 全球宏觀經濟不確定性：高通膨、高利率環境及經濟成長趨緩，可能抑制消費性電子產品的整體需求。 消費性電子需求復甦緩慢：若PC、NB及部分消費性電子產品需求復甦不如預期，將影響DDI及SoC出貨。 地緣政治風險：國際貿易情勢變化可能影響供應鏈穩定及終端市場需求。 新產品導入進度與市場接受度：新開發的ASIC或AI相關晶片，其市場導入時程與客戶接受度仍具不確定性。 整體而言，聯詠在2025年的成長將高度依賴OLED市場的發展以及車用等新興應用的拓展速度。公司需要在技術上持續領先，並有效應對成熟市場的競爭，才能維持穩健的獲利能力。 二、 市場分析與公司未來展望  市場分析師普遍關注瑞昱在PC市場的復甦力道、Wi-Fi規格升級（Wi-Fi 6/6E至Wi-Fi 7）的進程、車用乙太網路及音訊晶片的成長潛力，以及企業級網通產品的拓展。  瑞昱管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：  2025年第二季財務預測： 營收預計將較第一季成長低至中個位數百分比（low to mid single-digit %）。 毛利率預計介於 44% 至 46% 之間。 營業利益率預計將與第一季持平或略增。 2025年全年展望： 公司預期2025年將是復甦的一年，主要動能來自PC市場的換機潮（可能受AI PC及新作業系統帶動）以及網通產品的規格升級。 Wi-Fi 6/6E將持續是市場主流，Wi-Fi 7產品預計在下半年開始逐步放量貢獻營收。 車用乙太網路、音訊解決方案及企業級交換器等產品線預期將有不錯的成長。 TV SoC業務則視整體電視市場需求而定。 分析師認為，PC市場若能如預期因AI PC及企業換機潮而復甦，將對瑞昱營收帶來正面助益。Wi-Fi 7的滲透速度及ASP（平均銷售價格）的穩定性，以及在車用、企業市場的拓展成效，將是影響其長期成長的關鍵。  三、 影響營運的主要正面與負面因素  綜合來看，影響瑞昱近期財務表現及未來展望的因素如下：  主要正面因素：  PC/NB市場復甦：預期AI PC的推出、企業換機需求以及新作業系統的導入，將帶動PC市場需求回溫。 Wi-Fi規格升級：Wi-Fi 6/6E持續取代舊規格成為主流，且Wi-Fi 7開始導入高階市場，帶動產品ASP提升與出貨量增加。 車用電子成長：車用乙太網路晶片、音訊編解碼晶片在汽車智慧化及連網化趨勢下需求增加。 企業網通需求：企業級交換器、光纖網路控制器（PON）等產品受惠於頻寬升級需求。 庫存健康化：經過一段時間的調整，供應鏈庫存回到較健康水位，有利於訂單的穩定性。 音訊與TV產品穩定：Audio Codec持續保有高市佔率，TV SoC則視市場狀況穩定貢獻。 主要負面因素與挑戰：\n\n問題：公司遠傳的同期的財報表現差異為何？\n\n答案（請使用繁體中文回答）：根據所提供的資訊，無法直接比較遠傳與瑞昱在同一時期的財報表現。然而，我們可以從所提供的資訊中，列出影響兩家公司財報表現的主要因素，以協助您比較和分析：\n\n遠傳：\n1. 營收：主要來自行動通訊服務、寬頻上網、機上盒及MOD等業務。\n2. 毛利：主要來自行動通訊服務、寬頻上網及機上盒等業務。\n3. 營業費用：包括銷售費用、管理費用及研發費用等。\n4. 稅前淨利：為公司稅前盈利。\n5. 每股稅後盈餘（EPS）：為公司每股稅後盈利。\n\n瑞昱：\n1. 營收：主要來自IC設計服務、晶圓代工及封測等業務。\n2. 毛利：主要來自IC設計服務及晶圓代工等業務。\n3. 營業費用：包括銷售費用、管理費用及研發費用等。\n4. 稅前淨利：為公司稅前盈利。\n5. 每股稅後盈餘（EPS）：為公司每股稅後盈利。\n\n比較因素：\n1. 業務性質：遠傳為電信業者，主要提供行動通訊、寬頻上網等服務；瑞昱為IC設計公司，主要提供IC設計服務、晶圓代工及封測等業務。\n2. 營收來源：遠傳的營收來源主要為服務收入，瑞昱的營收來源則包括服務收入及產品銷售收入。\n3. 毛利率：遠傳的毛利率可能較高，因其主要為服務收入，而服務收入通常具有較高的毛利。瑞昱的毛利率可能較低，因其產品銷售收入佔比較高。\n4. 營業費用：兩家公司的營業費用結構可能不同，例如遠傳可能有較多的行銷費用，而瑞昱可能有較多的研發費用。\n5. 稅前\n-----------------------------------\n========== RAG 查詢結束 ==========\n  問題 '公司遠傳的同期的財報表現差異為何？' 的 RAG 查詢完成。\n    生成答案: 請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n三、 影響營運的主要正面與負面因素  綜合來看，影響祥碩近期財務表現及未來展望的因素如下：  主要正面因素：  與主要客戶（AMD）的緊密合作：AMD在CPU市場市佔率的提升，直接帶動祥碩晶片組及高速介面控制晶片的需求。 技術領先優勢：在USB4、PCIe Gen5/Gen6等高速傳輸介面技術上保持領先，受惠於新技術標準的升級週期。 AI與HPC需求帶動：數據中心、AI伺服器等高效能運算應用對高速傳輸介面需求強勁。 新產品與新市場：USB4 v2產品的開發、車用市場的佈局以及Techpoint的併購，為未來成長增添動能。 穩健的財務結構：持續維持高毛利率（約50%以上）、低負債比及充裕的現金部位。 特定市場競爭格局有利：如在中國市場特定產品線的競爭相對有限。 主要負面因素與挑戰：  半導體產業的週期性波動：整體產業景氣循環仍可能對公司營運帶來影響。 技術快速迭代的研發壓力：為維持技術領先，需持續投入高額研發費用。 全球供應鏈風險：需有效管理晶圓產能取得及供應商關係。 市場競爭：雖然在特定領域具領先優勢，但整體IC設計產業競爭依然存在，需專注技術差異化以避免價格戰。 對主要客戶的依賴性：主要客戶的市場表現與採購策略對祥碩營運有顯著影響。 毛利率波動：雖維持高檔，但仍可能受產品組合、市場競爭等因素影響而波動。 整體而言，祥碩憑藉其在高速傳輸技術的領導地位及與關鍵客戶的深度合作，在AI與HPC趨勢的帶動下，2025年營運前景看好。市場將持續關注其新產品的市場滲透速度、主要客戶的拉貨動能以及整體產業的復甦情況。 三、 影響營運的主要正面與負面因素  綜合來看，影響聯詠近期財務表現及未來展望的因素如下：  主要正面因素：  OLED滲透率提升：OLED面板在智慧型手機、穿戴裝置、平板、筆電及高階電視的應用持續擴大，帶動OLED DDI需求強勁成長。 TV市場回溫與規格升級：大型體育賽事（如奧運）可能刺激TV換機潮，且TV SoC規格持續升級（如8K、高刷新率、AI影像處理）。 車用電子成長潛力：汽車智慧化及電子化趨勢，帶動車用顯示器驅動IC、時序控制晶片(TCON)、影像感測器(CIS)等產品需求。 ASIC與AI相關機會：投入客製化晶片（ASIC）開發，以及佈局邊緣運算AI相關的影像處理SoC。 供應鏈庫存健康化：若終端市場庫存水位恢復健康，有利於訂單能見度及拉貨動能。 主要負面因素與挑戰：  成熟產品價格競爭：LCD DDI等成熟市場面臨來自中國大陸及其他競爭對手的價格壓力。 全球宏觀經濟不確定性：高通膨、高利率環境及經濟成長趨緩，可能抑制消費性電子產品的整體需求。 消費性電子需求復甦緩慢：若PC、NB及部分消費性電子產品需求復甦不如預期，將影響DDI及SoC出貨。 地緣政治風險：國際貿易情勢變化可能影響供應鏈穩定及終端市場需求。 新產品導入進度與市場接受度：新開發的ASIC或AI相關晶片，其市場導入時程與客戶接受度仍具不確定性。 整體而言，聯詠在2025年的成長將高度依賴OLED市場的發展以及車用等新興應用的拓展速度。公司需要在技術上持續領先，並有效應對成熟市場的競爭，才能維持穩健的獲利能力。 二、 市場分析與公司未來展望  市場分析師普遍關注瑞昱在PC市場的復甦力道、Wi-Fi規格升級（Wi-Fi 6/6E至Wi-Fi 7）的進程、車用乙太網路及音訊晶片的成長潛力，以及企業級網通產品的拓展。  瑞昱管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：  2025年第二季財務預測： 營收預計將較第一季成長低至中個位數百分比（low to mid single-digit %）。 毛利率預計介於 44% 至 46% 之間。 營業利益率預計將與第一季持平或略增。 2025年全年展望： 公司預期2025年將是復甦的一年，主要動能來自PC市場的換機潮（可能受AI PC及新作業系統帶動）以及網通產品的規格升級。 Wi-Fi 6/6E將持續是市場主流，Wi-Fi 7產品預計在下半年開始逐步放量貢獻營收。 車用乙太網路、音訊解決方案及企業級交換器等產品線預期將有不錯的成長。 TV SoC業務則視整體電視市場需求而定。 分析師認為，PC市場若能如預期因AI PC及企業換機潮而復甦，將對瑞昱營收帶來正面助益。Wi-Fi 7的滲透速度及ASP（平均銷售價格）的穩定性，以及在車用、企業市場的拓展成效，將是影響其長期成長的關鍵。  三、 影響營運的主要正面與負面因素  綜合來看，影響瑞昱近期財務表現及未來展望的因素如下：  主要正面因素：  PC/NB市場復甦：預期AI PC的推出、企業換機需求以及新作業系統的導入，將帶動PC市場需求回溫。 Wi-Fi規格升級：Wi-Fi 6/6E持續取代舊規格成為主流，且Wi-Fi 7開始導入高階市場，帶動產品ASP提升與出貨量增加。 車用電子成長：車用乙太網路晶片、音訊編解碼晶片在汽車智慧化及連網化趨勢下需求增加。 企業網通需求：企業級交換器、光纖網路控制器（PON）等產品受惠於頻寬升級需求。 庫存健康化：經過一段時間的調整，供應鏈庫存回到較健康水位，有利於訂單的穩定性。 音訊與TV產品穩定：Audio Codec持續保有高市佔率，TV SoC則視市場狀況穩定貢獻。 主要負面因素與挑戰：\n\n問題：公司遠傳的同期的財報表現差異為何？\n\n答案（請使用繁體中文回答）：根據所提供的資訊，無法直接比較遠傳與瑞昱在同一時期的財報表現。然而，我們可以從所提供的資訊中，列出影響兩家公司財報表現的主要因素，以協助您比較和分析：\n\n遠傳：\n1. 營收：主要來自行動通訊服務、寬頻上網、機上盒及MOD等業務。\n2. 毛利：主要來自行動通訊服務、寬頻上網及機上盒等業務。\n3. 營業費用：包括銷售費用、管理費用及研發費用等。\n4. 稅前淨利：為公司稅前盈利。\n5. 每股稅後盈餘（EPS）：為公司每股稅後盈利。\n\n瑞昱：\n1. 營收：主要來自IC設計服務、晶圓代工及封測等業務。\n2. 毛利：主要來自IC設計服務及晶圓代工等業務。\n3. 營業費用：包括銷售費用、管理費用及研發費用等。\n4. 稅前淨利：為公司稅前盈利。\n5. 每股稅後盈餘（EPS）：為公司每股稅後盈利。\n\n比較因素：\n1. 業務性質：遠傳為電信業者，主要提供行動通訊、寬頻上網等服務；瑞昱為IC設計公司，主要提供IC設計服務、晶圓代工及封測等業務。\n2. 營收來源：遠傳的營收來源主要為服務收入，瑞昱的營收來源則包括服務收入及產品銷售收入。\n3. 毛利率：遠傳的毛利率可能較高，因其主要為服務收入，而服務收入通常具有較高的毛利。瑞昱的毛利率可能較低，因其產品銷售收入佔比較高。\n4. 營業費用：兩家公司的營業費用結構可能不同，例如遠傳可能有較多的行銷費用，而瑞昱可能有較多的研發費用。\n5. 稅前\n    檢索到的上下文數量: 3\n正在處理問題 3/3: '聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？'\n\n========== 開始 RAG 查詢 ==========\n步驟 1: 定義要問 LLM 的問題: \"聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\"\n\n步驟 2: 為 \"聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\" 檢索上下文...\n  正在嵌入問題...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1be8f31386f44c0db5d3e8296cd540fb"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"  問題嵌入完成。形狀: (1, 1024)\n  正在 FAISS 索引中搜索相似區塊 (k=3)...\n  搜索完成。找到索引: [[ 2  1 35]]\n  成功提取 3 個上下文區塊。\n\n步驟 3: 使用檢索到的上下文查詢 LLM...\nLLM 將回答的問題: 聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\n\n--- 模型基於上下文生成的答案 ---\n請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n二、 市場分析與公司未來展望  市場分析師普遍看好聯發科在手機市場，特別是旗艦級SoC（系統單晶片）的競爭力，並預期AI在終端裝置的滲透將為其帶來新的成長機會。此外，公司在Wi-Fi 7、車用電子、電源管理IC（PMIC）等領域的拓展也受到關注。  聯發科管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：  2025年第二季財務預測： 營收預計介於新台幣 1420 億元至 1508 億元之間（預期季增約5%至11%）。 毛利率預計介於 47.5% 至 49.5% 之間（中位數為48.5%）。 2025年全年展望： 公司預期2025年全年美元營收將實現中雙位數（mid-teens，約14-16%）的年成長。 手機業務預計將有顯著成長，主要由旗艦和高階市場的市佔率提升及規格升級帶動。 智慧裝置平台業務（包括電視晶片、Wi-Fi、ASIC、車用等）預期也將持續成長。 AI將是重要成長催化劑，無論是手機SoC整合的AI處理單元，或是針對邊緣運算裝置的AI晶片。 分析師認為，聯發科的天璣系列處理器在效能與功耗上已具備與主要競爭對手抗衡的實力，有助於其在高階市場持續擴大份額。  三、 影響營運的主要正面與負面因素  綜合來看，影響聯發科近期財務表現及未來展望的因素如下：  主要正面因素：  旗艦手機晶片強勁：天璣系列（如天璣9400及後續產品）在效能、AI運算能力及功耗上的競爭力，帶動高階手機市場的市佔率提升和平均售價(ASP)上揚。 AI技術整合與邊緣AI商機：AI在手機、IoT裝置、汽車等邊緣運算平台的應用，為聯發科的晶片帶來新的需求與價值。 多元化產品組合：在智慧裝置平台業務，如Wi-Fi 7晶片、電視SoC、ASIC（客製化晶片）、車用電子、電源管理IC等領域的持續成長，降低對單一市場的依賴。 市場庫存健康：經過調整後，手機供應鏈庫存回到健康水位，有利於訂單穩定。 中國市場復甦與升級：中國手機市場若持續復甦並朝向規格升級，將有利於聯發科的出貨。 主要負面因素與挑戰： 聯發科的客戶群體主要是全球各大終端產品品牌商和原始設計製造商 (ODM)。雖然聯發科通常不公開其具體客戶名單，但其客戶主要屬於以下產業或類型：  智慧型手機品牌商：涵蓋全球多個主要的手機製造商。 消費性電子產品製造商：生產智慧電視、平板電腦、路由器、智慧音箱、穿戴裝置等的廠商。 物聯網設備開發商：涵蓋工業、零售、醫療等多元領域。 汽車零組件供應商及汽車製造商：在智慧汽車領域的合作夥伴。 雲端服務供應商及企業客戶：在客製化AI晶片領域的潛在及現有客戶。 主要營收來源：  聯發科的營收主要來自其各類晶片產品的銷售。根據近期（截至2024年底及2025年第一季）的公開資訊，其主要營收來源大致如下：  行動通訊 (Mobile Phone)：主要為智慧型手機處理器等。在2025年第一季，此部分約佔總營收的 56%。 智慧終端平台 (Smart Edge Platforms)：此類別涵蓋智慧家庭（如電視、路由器）、平板電腦、Chromebook、物聯網、ASIC（客製化晶片）、車用電子等。在2025年第一季，此部分約佔總營收的 38%。 電源管理IC (Power IC)：約佔總營收的 6% (2025年第一季數據)。 具體各產品線的營收佔比會因市場需求、新產品週期及季節性因素而有所波動。近年來，除了穩固其在智慧型手機市場的地位外，聯發科也積極拓展在智慧物聯網、汽車電子以及AI相關領域的市場，以實現營收來源的多元化。  一、 最近期財報表現 (2025年第一季)  聯發科最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現穩健：  營收：新台幣 1355 億元（年增約 32%，季減約 8%）。 毛利率：48.5%（符合公司預期，年增0.5個百分點）。 營業利益率：18.2%。 每股盈餘 (EPS)：約為新台幣 19.85 元。 公司指出，2025年第一季營收表現主要受惠於手機客戶庫存回補以及旗艦手機晶片（如天璣9400系列）出貨暢旺。智慧裝置平台（Smart Edge Platform）業務也維持成長動能。  二、 市場分析與公司未來展望 主要產品應用終端市場：  聯詠科技的晶片被廣泛應用於各種消費性電子、電腦資訊及通訊產品，主要終端市場包括：  電視 (TV)：提供顯示器驅動IC及TV SoC。 桌上型顯示器 (Monitor)：提供顯示器驅動IC。 筆記型電腦 (Notebook PC) 及平板電腦 (Tablet)：提供顯示器驅動IC及觸控暨顯示驅動整合晶片 (TDDI)。 智慧型手機 (Smartphone)：提供AMOLED驅動IC、TDDI等。 汽車電子 (Automotive)：提供車用顯示器驅動IC、影像感測器相關晶片等，是近年積極拓展的領域。 穿戴式裝置 (Wearable Devices)：例如智慧手錶的顯示驅動IC。 虛擬實境/擴增實境 (VR/AR)：提供相關顯示解決方案。 工業及醫療顯示 (Industrial/Medical Display)：提供利基型顯示器驅動IC。 安防監控 (Surveillance)：提供影像處理SoC。 主要客戶群體：  聯詠科技的客戶主要是全球各大面板製造商、品牌電子產品製造商及原始設計製造商 (ODM)。由於商業保密原則，聯詠通常不公開其主要客戶的具體名單。其客戶主要屬於以下產業或類型：  全球主要的面板製造商：為其提供各種尺寸面板所需的驅動IC。 電視品牌商及代工廠。 筆記型電腦及桌上型顯示器品牌商及代工廠。 智慧型手機品牌商及代工廠。 汽車電子零組件供應商及車廠。 消費性電子產品製造商。 主要營收來源：  聯詠科技的營收主要來自其兩大產品線：顯示器驅動IC (DDI) 和系統單晶片 (SoC)。根據近期（截至2024年底及2025年初）的法人報告與市場分析，其營收佔比大致如下：  顯示器驅動IC (DDI)：此為聯詠最主要的營收來源，預估佔公司整體營收約 65% - 75%。其中，大尺寸DDI (應用於電視、顯示器、筆電) 和中小尺寸DDI (應用於手機、平板、穿戴、車用等) 均有重要貢獻。 系統單晶片 (SoC)：此部分營收約佔公司整體營收約 25% - 35%。主要產品包括TV SoC、時序控制晶片 (TCON) 及其他影像相關SoC。 （請注意：以上營收佔比為概略預估，實際數字會隨每季財報及市場狀況而有所變動。）\n\n問題：聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\n\n答案（請使用繁體中文回答）：根據所提供的上下文資料，聯發科在 AI 晶片市場的最新進展為：\n\n1. 在手機SoC整合的AI處理單元方面，聯發科的天璣系列處理器已具備與主要競爭對手抗衡的實力，有助於其在高階市場持續擴大份額。\n2. 在邊緣運算裝置的AI晶片方面，聯發科正積極開拓相關市場，將AI技術應用於物聯網、智慧家庭、車用電子等領域。\n3. 聯發科的AI晶片產品線包括智慧手機晶片、智慧裝置平台晶片、車用電子晶片等，顯示出該公司在AI晶片市場多元化的發展策略。\n\n主要競爭對手包括：\n\n1. 高通（Qualcomm）：作為全球知名的半導體公司之一，高通在手機晶片市場佔有重要地位。其Snapdragon系列處理器在高階手機市場廣受歡迎，並支援AI、5G等先進技術。\n2. 安謀（Arm）：安謀是全球領先的處理器架構設計公司，其晶片設計被廣泛應用於移動裝置、伺服器、物聯網等領域。在AI晶片市場，安謀也推出多款支援AI運算的處理器，如Cortex-M4、Cortex-A72等。\n3. 英特爾（Intel）：英特爾是全球最大的半導體製造商之一，其在AI晶片市場亦佔有重要地位。例如，其Xeon Phi系列處理器專為高效能運算和AI應用而設計；其Movidius系列晶片則專為物聯網和邊緣運算裝置而設計。\n4. NVIDIA：NVIDIA是全球知名的圖形處理器（GPU）製造商，其在AI晶片市場亦具有領先地位。例如，其Tegra系列晶片用於車用電子、物聯網等領域；其V100系列晶片則是專為資料中心和雲端運算而設計。\n5. AMD（超微）：AMD是另一家全球知名的半導體\n-----------------------------------\n========== RAG 查詢結束 ==========\n  問題 '聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？' 的 RAG 查詢完成。\n    生成答案: 請根據以下提供的上下文資料來回答問題。如果你在上下文中找不到答案，請說你找不到相關資訊，不要試圖編造答案。\n\n上下文：\n二、 市場分析與公司未來展望  市場分析師普遍看好聯發科在手機市場，特別是旗艦級SoC（系統單晶片）的競爭力，並預期AI在終端裝置的滲透將為其帶來新的成長機會。此外，公司在Wi-Fi 7、車用電子、電源管理IC（PMIC）等領域的拓展也受到關注。  聯發科管理層在2025年4月底的法人說明會上，對未來營運釋出了以下展望：  2025年第二季財務預測： 營收預計介於新台幣 1420 億元至 1508 億元之間（預期季增約5%至11%）。 毛利率預計介於 47.5% 至 49.5% 之間（中位數為48.5%）。 2025年全年展望： 公司預期2025年全年美元營收將實現中雙位數（mid-teens，約14-16%）的年成長。 手機業務預計將有顯著成長，主要由旗艦和高階市場的市佔率提升及規格升級帶動。 智慧裝置平台業務（包括電視晶片、Wi-Fi、ASIC、車用等）預期也將持續成長。 AI將是重要成長催化劑，無論是手機SoC整合的AI處理單元，或是針對邊緣運算裝置的AI晶片。 分析師認為，聯發科的天璣系列處理器在效能與功耗上已具備與主要競爭對手抗衡的實力，有助於其在高階市場持續擴大份額。  三、 影響營運的主要正面與負面因素  綜合來看，影響聯發科近期財務表現及未來展望的因素如下：  主要正面因素：  旗艦手機晶片強勁：天璣系列（如天璣9400及後續產品）在效能、AI運算能力及功耗上的競爭力，帶動高階手機市場的市佔率提升和平均售價(ASP)上揚。 AI技術整合與邊緣AI商機：AI在手機、IoT裝置、汽車等邊緣運算平台的應用，為聯發科的晶片帶來新的需求與價值。 多元化產品組合：在智慧裝置平台業務，如Wi-Fi 7晶片、電視SoC、ASIC（客製化晶片）、車用電子、電源管理IC等領域的持續成長，降低對單一市場的依賴。 市場庫存健康：經過調整後，手機供應鏈庫存回到健康水位，有利於訂單穩定。 中國市場復甦與升級：中國手機市場若持續復甦並朝向規格升級，將有利於聯發科的出貨。 主要負面因素與挑戰： 聯發科的客戶群體主要是全球各大終端產品品牌商和原始設計製造商 (ODM)。雖然聯發科通常不公開其具體客戶名單，但其客戶主要屬於以下產業或類型：  智慧型手機品牌商：涵蓋全球多個主要的手機製造商。 消費性電子產品製造商：生產智慧電視、平板電腦、路由器、智慧音箱、穿戴裝置等的廠商。 物聯網設備開發商：涵蓋工業、零售、醫療等多元領域。 汽車零組件供應商及汽車製造商：在智慧汽車領域的合作夥伴。 雲端服務供應商及企業客戶：在客製化AI晶片領域的潛在及現有客戶。 主要營收來源：  聯發科的營收主要來自其各類晶片產品的銷售。根據近期（截至2024年底及2025年第一季）的公開資訊，其主要營收來源大致如下：  行動通訊 (Mobile Phone)：主要為智慧型手機處理器等。在2025年第一季，此部分約佔總營收的 56%。 智慧終端平台 (Smart Edge Platforms)：此類別涵蓋智慧家庭（如電視、路由器）、平板電腦、Chromebook、物聯網、ASIC（客製化晶片）、車用電子等。在2025年第一季，此部分約佔總營收的 38%。 電源管理IC (Power IC)：約佔總營收的 6% (2025年第一季數據)。 具體各產品線的營收佔比會因市場需求、新產品週期及季節性因素而有所波動。近年來，除了穩固其在智慧型手機市場的地位外，聯發科也積極拓展在智慧物聯網、汽車電子以及AI相關領域的市場，以實現營收來源的多元化。  一、 最近期財報表現 (2025年第一季)  聯發科最近公布的財報為2025年第一季（截至2025年3月31日），其主要財務數據表現穩健：  營收：新台幣 1355 億元（年增約 32%，季減約 8%）。 毛利率：48.5%（符合公司預期，年增0.5個百分點）。 營業利益率：18.2%。 每股盈餘 (EPS)：約為新台幣 19.85 元。 公司指出，2025年第一季營收表現主要受惠於手機客戶庫存回補以及旗艦手機晶片（如天璣9400系列）出貨暢旺。智慧裝置平台（Smart Edge Platform）業務也維持成長動能。  二、 市場分析與公司未來展望 主要產品應用終端市場：  聯詠科技的晶片被廣泛應用於各種消費性電子、電腦資訊及通訊產品，主要終端市場包括：  電視 (TV)：提供顯示器驅動IC及TV SoC。 桌上型顯示器 (Monitor)：提供顯示器驅動IC。 筆記型電腦 (Notebook PC) 及平板電腦 (Tablet)：提供顯示器驅動IC及觸控暨顯示驅動整合晶片 (TDDI)。 智慧型手機 (Smartphone)：提供AMOLED驅動IC、TDDI等。 汽車電子 (Automotive)：提供車用顯示器驅動IC、影像感測器相關晶片等，是近年積極拓展的領域。 穿戴式裝置 (Wearable Devices)：例如智慧手錶的顯示驅動IC。 虛擬實境/擴增實境 (VR/AR)：提供相關顯示解決方案。 工業及醫療顯示 (Industrial/Medical Display)：提供利基型顯示器驅動IC。 安防監控 (Surveillance)：提供影像處理SoC。 主要客戶群體：  聯詠科技的客戶主要是全球各大面板製造商、品牌電子產品製造商及原始設計製造商 (ODM)。由於商業保密原則，聯詠通常不公開其主要客戶的具體名單。其客戶主要屬於以下產業或類型：  全球主要的面板製造商：為其提供各種尺寸面板所需的驅動IC。 電視品牌商及代工廠。 筆記型電腦及桌上型顯示器品牌商及代工廠。 智慧型手機品牌商及代工廠。 汽車電子零組件供應商及車廠。 消費性電子產品製造商。 主要營收來源：  聯詠科技的營收主要來自其兩大產品線：顯示器驅動IC (DDI) 和系統單晶片 (SoC)。根據近期（截至2024年底及2025年初）的法人報告與市場分析，其營收佔比大致如下：  顯示器驅動IC (DDI)：此為聯詠最主要的營收來源，預估佔公司整體營收約 65% - 75%。其中，大尺寸DDI (應用於電視、顯示器、筆電) 和中小尺寸DDI (應用於手機、平板、穿戴、車用等) 均有重要貢獻。 系統單晶片 (SoC)：此部分營收約佔公司整體營收約 25% - 35%。主要產品包括TV SoC、時序控制晶片 (TCON) 及其他影像相關SoC。 （請注意：以上營收佔比為概略預估，實際數字會隨每季財報及市場狀況而有所變動。）\n\n問題：聯發科在 AI 晶片市場的最新進展是什麼？其主要競爭對手有哪些？\n\n答案（請使用繁體中文回答）：根據所提供的上下文資料，聯發科在 AI 晶片市場的最新進展為：\n\n1. 在手機SoC整合的AI處理單元方面，聯發科的天璣系列處理器已具備與主要競爭對手抗衡的實力，有助於其在高階市場持續擴大份額。\n2. 在邊緣運算裝置的AI晶片方面，聯發科正積極開拓相關市場，將AI技術應用於物聯網、智慧家庭、車用電子等領域。\n3. 聯發科的AI晶片產品線包括智慧手機晶片、智慧裝置平台晶片、車用電子晶片等，顯示出該公司在AI晶片市場多元化的發展策略。\n\n主要競爭對手包括：\n\n1. 高通（Qualcomm）：作為全球知名的半導體公司之一，高通在手機晶片市場佔有重要地位。其Snapdragon系列處理器在高階手機市場廣受歡迎，並支援AI、5G等先進技術。\n2. 安謀（Arm）：安謀是全球領先的處理器架構設計公司，其晶片設計被廣泛應用於移動裝置、伺服器、物聯網等領域。在AI晶片市場，安謀也推出多款支援AI運算的處理器，如Cortex-M4、Cortex-A72等。\n3. 英特爾（Intel）：英特爾是全球最大的半導體製造商之一，其在AI晶片市場亦佔有重要地位。例如，其Xeon Phi系列處理器專為高效能運算和AI應用而設計；其Movidius系列晶片則專為物聯網和邊緣運算裝置而設計。\n4. NVIDIA：NVIDIA是全球知名的圖形處理器（GPU）製造商，其在AI晶片市場亦具有領先地位。例如，其Tegra系列晶片用於車用電子、物聯網等領域；其V100系列晶片則是專為資料中心和雲端運算而設計。\n5. AMD（超微）：AMD是另一家全球知名的半導體\n    檢索到的上下文數量: 3\n\n所有問題的數據收集完畢！\n\n已使用 Notebook 中的變數成功創建包含多個問答對的 RAGAS 評估數據集:\nDataset({\n    features: ['question', 'answer', 'contexts'],\n    num_rows: 1\n})\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install ragas datasets langchain-google-genai langchain_huggingface --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:03:09.291547Z","iopub.execute_input":"2025-05-26T03:03:09.291737Z","iopub.status.idle":"2025-05-26T03:04:26.366558Z","shell.execute_reply.started":"2025-05-26T03:03:09.291717Z","shell.execute_reply":"2025-05-26T03:04:26.365740Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    user_secrets = UserSecretsClient()\n    google_api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\") # 假設您在 Kaggle Secrets 中儲存的名稱是 \"GOOGLE_API_KEY\"\n    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n    print(\"成功從 Kaggle Secrets 讀取並設定 GOOGLE_API_KEY。\")\nexcept Exception as e:\n    print(f\"從 Kaggle Secrets 讀取 'GOOGLE_API_KEY' 失敗: {e}\")\n    # 根據您的錯誤處理策略，可能需要 exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:04:26.367637Z","iopub.execute_input":"2025-05-26T03:04:26.367951Z","iopub.status.idle":"2025-05-26T03:04:26.443811Z","shell.execute_reply.started":"2025-05-26T03:04:26.367917Z","shell.execute_reply":"2025-05-26T03:04:26.443244Z"}},"outputs":[{"name":"stdout","text":"成功從 Kaggle Secrets 讀取並設定 GOOGLE_API_KEY。\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from datasets import Dataset\nfrom ragas import evaluate\nfrom ragas.metrics import (\n    faithfulness,\n    answer_relevancy,\n    context_precision,\n)\n# from langchain_openai import ChatOpenAI # 原本的 OpenAI LLM\nfrom langchain_google_genai import ChatGoogleGenerativeAI # <<< 導入 Gemini LLM\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\n\n# LLM 配置 (改用 Gemini)\n# ragas_llm_gpt4o = ChatOpenAI(model=\"gpt-4o\", temperature=0) # 原本的\ntry:\n    ragas_llm_gemini = ChatGoogleGenerativeAI(\n        model=\"gemini-2.5-flash-preview-05-20\", # 或者您想使用的特定 Gemini 模型，例如 \"gemini-1.5-pro-latest\"\n        temperature=0,\n        # convert_system_message_to_human=True # 有些舊版本可能需要，視情況調整\n    )\n    print(f\"已配置 RAGAS 使用 LLM: Gemini ({ragas_llm_gemini.model})\") # 確認模型名稱\nexcept Exception as e:\n    print(f\"配置 ChatGoogleGenerativeAI 失敗: {e}\")\n    # 設定一個備用或拋出錯誤\n    ragas_llm_gemini = None\n\n\ntry:\n    model_name_stella = 'infgrad/stella-large-zh-v2'\n    # 您可能需要確保 Kaggle 環境能下載並使用這個模型，且有足夠的 RAM\n    # 在 Kaggle Notebook 設定中開啟網路，並確保有足夠的磁碟空間\n    ragas_embeddings = HuggingFaceEmbeddings(\n        model_name=model_name_stella,\n        # model_kwargs={'device': 'cuda'}, # 如果有 GPU 且 Langchain 版本支持\n        # encode_kwargs={'normalize_embeddings': True} # 根據模型推薦\n    )\n    print(f\"已配置 RAGAS 使用 Embeddings: {model_name_stella}\")\nexcept Exception as e:\n    print(f\"配置 HuggingFace Embeddings ({model_name_stella}) 失敗: {e}\")\n\nprint(\"評估數據集 (`dataset`) 準備完成:\")\nprint(dataset)\nprint(f\"共 {len(dataset)} 個評估樣本。\\n\")\n\n# 步驟 4: 執行 RAGAS 評估\nif os.getenv(\"GOOGLE_API_KEY\") and ragas_llm_gemini is not None: # 確保 API Key 和 LLM 都已設定\n    print(f\"開始使用 Gemini 進行 RAGAS 評估 (基於 `dataset` 變數)...\")\n    try:\n        result = evaluate(\n            dataset,\n            metrics=[\n                faithfulness,\n                answer_relevancy,\n            ],\n            llm=ragas_llm_gemini, # <<< 在此處傳入 Gemini LLM 實例\n            embeddings=ragas_embeddings, # 嵌入模型可以保持不變，或根據需求調整\n            raise_exceptions=True\n        )\n\n        print(\"\\\\nGemini 評估完成！\")\n        # ... (後續結果處理不變) ...\n\n    except Exception as e:\n        print(f\"\\\\n執行 RAGAS 評估時發生錯誤: {e}\")\nelse:\n    print(\"由於 GOOGLE_API_KEY 未設定或 Gemini LLM 未成功初始化，無法執行 RAGAS 評估。\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:04:26.444563Z","iopub.execute_input":"2025-05-26T03:04:26.444846Z","iopub.status.idle":"2025-05-26T03:05:22.968047Z","shell.execute_reply.started":"2025-05-26T03:04:26.444819Z","shell.execute_reply":"2025-05-26T03:05:22.967448Z"}},"outputs":[{"name":"stdout","text":"已配置 RAGAS 使用 LLM: Gemini (models/gemini-2.5-flash-preview-05-20)\n已配置 RAGAS 使用 Embeddings: infgrad/stella-large-zh-v2\n評估數據集 (`dataset`) 準備完成:\nDataset({\n    features: ['question', 'answer', 'contexts'],\n    num_rows: 1\n})\n共 1 個評估樣本。\n\n開始使用 Gemini 進行 RAGAS 評估 (基於 `dataset` 變數)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f4ab34cd964847a69fa03cdb34df17"}},"metadata":{}},{"name":"stdout","text":"\\nGemini 評估完成！\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:05:22.968780Z","iopub.execute_input":"2025-05-26T03:05:22.968972Z","iopub.status.idle":"2025-05-26T03:05:22.973536Z","shell.execute_reply.started":"2025-05-26T03:05:22.968957Z","shell.execute_reply":"2025-05-26T03:05:22.972966Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'faithfulness': 0.3704, 'answer_relevancy': 1.0000}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"import pickle\nwith open('all_chunks.pkl', 'wb') as f:\n    pickle.dump(all_chunks, f)\n\nwith open('all_file_names.pkl', 'wb') as f:\n    pickle.dump(all_file_names, f)\n\nfaiss.write_index(index, \"my_company_index.faiss\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:05:22.974317Z","iopub.execute_input":"2025-05-26T03:05:22.974532Z","iopub.status.idle":"2025-05-26T03:05:22.999884Z","shell.execute_reply.started":"2025-05-26T03:05:22.974517Z","shell.execute_reply":"2025-05-26T03:05:22.999210Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}